{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üõ¨ AI-Based Landing Zone Safety Classification\n",
                "\n",
                "## üß© Problem Statement\n",
                "\n",
                "### What is the Problem?\n",
                "Drones need to land safely. Before landing, a drone must check if the ground is:\n",
                "- **Flat** (not too steep)\n",
                "- **Smooth** (not too rough)\n",
                "- **Clear** (no obstacles or vegetation)\n",
                "\n",
                "### Real-Life Analogy üõ©Ô∏è\n",
                "Think of landing a paper airplane - you want a **flat table**, not stairs!\n",
                "\n",
                "### ü™ú Steps to Solve\n",
                "1. **Load Data** - Get terrain features\n",
                "2. **Explore Data** - Understand what each feature means\n",
                "3. **Prepare Data** - Split into training/testing\n",
                "4. **Train Model** - Teach AI to classify safe/unsafe\n",
                "5. **Evaluate** - Check if model works well\n",
                "6. **Visualize** - Create safety heatmap\n",
                "7. **Recommend** - Suggest landing strategies\n",
                "\n",
                "### üéØ Expected Output\n",
                "- Trained ML model with >80% accuracy\n",
                "- Safety heatmap showing safe/unsafe zones\n",
                "- Landing recommendations for drones"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üì¶ Section 1: Import Libraries\n",
                "\n",
                "### üîπ Line Explanation: `import pandas as pd`\n",
                "\n",
                "#### 2.1 What the line does\n",
                "Loads the pandas library and gives it a short name `pd`.\n",
                "\n",
                "#### 2.2 Why it is used\n",
                "Pandas is like **Excel for Python** - it handles tables (DataFrames). Without it, we'd have to write 100s of lines for simple table operations.\n",
                "- **Is this the only way?** No, we could use basic Python lists, but that's 10x harder!\n",
                "- **Why better?** Pandas is optimized, tested, and has thousands of useful functions.\n",
                "\n",
                "#### 2.3 When to use it\n",
                "Whenever you work with tabular data (CSV, Excel, databases).\n",
                "\n",
                "#### 2.4 Where to use it\n",
                "- Data Science projects\n",
                "- Machine Learning pipelines\n",
                "- Business analytics\n",
                "\n",
                "#### 2.5 How to use it\n",
                "```python\n",
                "import pandas as pd\n",
                "df = pd.read_csv('data.csv')  # Load data\n",
                "df.head()  # Show first 5 rows\n",
                "```\n",
                "\n",
                "#### 2.6 How it works internally\n",
                "1. Python looks for `pandas` in installed packages\n",
                "2. Loads the module into memory\n",
                "3. Creates alias `pd` pointing to pandas\n",
                "\n",
                "#### 2.7 Output\n",
                "No visible output - just loads library silently."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import pandas - the data manipulation powerhouse\n",
                "import pandas as pd\n",
                "print(\"‚úÖ pandas loaded - version:\", pd.__version__)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Line Explanation: `import numpy as np`\n",
                "\n",
                "#### 2.1 What the line does\n",
                "Loads NumPy for numerical operations.\n",
                "\n",
                "#### 2.2 Why it is used\n",
                "NumPy is the **math engine** of Python. It handles arrays and mathematical operations 50x faster than basic Python.\n",
                "\n",
                "#### 2.3-2.7 Key Points\n",
                "- **When**: Working with numbers, arrays, matrices\n",
                "- **Where**: Scientific computing, ML, image processing\n",
                "- **How**: `np.array([1,2,3])` creates a fast array\n",
                "- **Internal**: Uses C code for speed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import numpy - the numerical computing foundation\n",
                "import numpy as np\n",
                "print(\"‚úÖ numpy loaded - version:\", np.__version__)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Visualization Libraries: matplotlib and seaborn\n",
                "\n",
                "#### 2.1 What they do\n",
                "- **matplotlib**: The basic plotting library (like MS Paint for charts)\n",
                "- **seaborn**: Beautiful statistical plots (like Photoshop for charts)\n",
                "\n",
                "#### 2.2 Why use both?\n",
                "- matplotlib = control over every detail\n",
                "- seaborn = beautiful plots with less code\n",
                "- They work together perfectly!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import visualization libraries\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Set style for beautiful plots\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "sns.set_palette('husl')\n",
                "print(\"‚úÖ Visualization libraries loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Scikit-learn Imports\n",
                "\n",
                "#### 2.1 What these imports do\n",
                "Load Machine Learning tools from sklearn:\n",
                "- `train_test_split`: Split data for training/testing\n",
                "- `RandomForestClassifier`: Our ML algorithm\n",
                "- Metrics: Measure how well model works\n",
                "\n",
                "#### 2.2 Why sklearn?\n",
                "It's the **Swiss Army knife** of ML in Python - has everything!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import sklearn components\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    confusion_matrix, roc_auc_score, roc_curve, classification_report\n",
                ")\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"‚úÖ All sklearn components loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üìä Task 1: Data Understanding\n",
                "\n",
                "### üîπ Loading the Dataset\n",
                "\n",
                "#### 2.1 What we're doing\n",
                "Loading landing zone data from a Google Sheets CSV.\n",
                "\n",
                "#### 2.2 Why\n",
                "Can't train a model without data! This is our \"textbook\" for teaching the AI.\n",
                "\n",
                "#### 2.3 When\n",
                "Always the FIRST step in any ML project.\n",
                "\n",
                "### ‚öôÔ∏è Function: `pd.read_csv()`\n",
                "\n",
                "#### 3.1 What it does\n",
                "Reads a CSV file and creates a DataFrame (table).\n",
                "\n",
                "#### 3.2 Why used\n",
                "CSV is the most common data format - simple text file with commas.\n",
                "\n",
                "#### 3.3 When to use\n",
                "When loading data from files or URLs.\n",
                "\n",
                "#### 3.4 Arguments\n",
                "- `filepath_or_buffer`: Path to file or URL (REQUIRED)\n",
                "- `sep=','`: Column separator (default: comma)\n",
                "- `header=0`: Row to use as column names\n",
                "\n",
                "#### 3.5 How it works internally\n",
                "1. Opens file/URL connection\n",
                "2. Reads line by line\n",
                "3. Splits each line by separator\n",
                "4. Creates DataFrame in memory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration constants\n",
                "RANDOM_STATE = 42  # For reproducibility\n",
                "TEST_SIZE = 0.2    # 20% for testing\n",
                "\n",
                "# Load data from Google Sheets\n",
                "data_url = \"https://docs.google.com/spreadsheets/d/1tCQf9YVzj8zET1bjTlettAV5WfyeNpo4EBEjo5H1Z9Y/export?format=csv\"\n",
                "\n",
                "try:\n",
                "    df = pd.read_csv(data_url)\n",
                "    print(f\"‚úÖ Data loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ö†Ô∏è Using sample data: {e}\")\n",
                "    np.random.seed(RANDOM_STATE)\n",
                "    n = 500\n",
                "    df = pd.DataFrame({\n",
                "        'slope_deg': np.random.uniform(0, 20, n),\n",
                "        'roughness': np.random.uniform(0, 1, n),\n",
                "        'edge_density': np.random.uniform(0, 1, n),\n",
                "        'ndvi_mean': np.random.uniform(0, 1, n),\n",
                "        'shadow_fraction': np.random.uniform(0, 0.7, n),\n",
                "        'brightness_std': np.random.uniform(0, 0.3, n),\n",
                "        'object_density': np.random.uniform(0, 0.7, n),\n",
                "        'confidence_score': np.random.uniform(0.5, 1, n),\n",
                "        'label': np.random.randint(0, 2, n)\n",
                "    })"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Viewing First Rows: `df.head()`\n",
                "\n",
                "#### 2.1 What it does\n",
                "Shows the first N rows of DataFrame (default: 5).\n",
                "\n",
                "#### 2.2 Why\n",
                "Quick sanity check - did data load correctly?\n",
                "\n",
                "#### 2.3 Real-life analogy\n",
                "Like peeking at the top of a stack of papers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# View first 5 rows\n",
                "print(\"üìã First 5 rows of data:\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Dataset Shape and Info\n",
                "\n",
                "#### 2.1 What we're checking\n",
                "- **Shape**: How many rows and columns?\n",
                "- **Info**: Data types and missing values\n",
                "- **Describe**: Statistical summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset shape\n",
                "print(f\"üìä Dataset Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
                "print(f\"\\nüìã Column Names: {list(df.columns)}\")\n",
                "\n",
                "# Data types\n",
                "print(\"\\nüìã Data Types:\")\n",
                "print(df.dtypes)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Statistical Summary: `df.describe()`\n",
                "\n",
                "#### 2.1 What it does\n",
                "Calculates count, mean, std, min, 25%, 50%, 75%, max for each column.\n",
                "\n",
                "#### 2.2 Why important\n",
                "- See data ranges (min/max)\n",
                "- Spot outliers\n",
                "- Understand distributions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistical summary\n",
                "print(\"üìä Statistical Summary:\")\n",
                "df.describe().round(3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Feature Explanations\n",
                "\n",
                "Understanding what each column means is CRITICAL!\n",
                "\n",
                "| Feature | Meaning | Safe = | Unsafe = |\n",
                "|---------|---------|--------|----------|\n",
                "| slope_deg | Ground steepness (degrees) | <10¬∞ | >15¬∞ |\n",
                "| roughness | Surface bumpiness | <0.3 | >0.5 |\n",
                "| edge_density | Sharp edges/obstacles | <0.3 | >0.5 |\n",
                "| ndvi_mean | Vegetation amount | <0.3 | >0.6 |\n",
                "| shadow_fraction | Shadow coverage | <0.3 | >0.5 |\n",
                "| brightness_std | Lighting variation | <0.1 | >0.2 |\n",
                "| object_density | Object count | <0.2 | >0.4 |\n",
                "| confidence_score | Detection certainty | >0.7 | <0.5 |\n",
                "| label | Target: Safe(1)/Unsafe(0) | 1 | 0 |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Class distribution\n",
                "print(\"üìä Class Distribution:\")\n",
                "class_counts = df['label'].value_counts()\n",
                "for label, count in class_counts.items():\n",
                "    status = \"‚úÖ SAFE\" if label == 1 else \"‚ùå UNSAFE\"\n",
                "    pct = 100 * count / len(df)\n",
                "    print(f\"   {status}: {count} ({pct:.1f}%)\")\n",
                "\n",
                "# Visualize\n",
                "plt.figure(figsize=(8, 5))\n",
                "colors = ['#ff6b6b', '#51cf66']\n",
                "plt.pie(class_counts, labels=['UNSAFE', 'SAFE'], colors=colors,\n",
                "        autopct='%1.1f%%', explode=[0.05, 0], startangle=90)\n",
                "plt.title('Landing Zone Safety Distribution', fontsize=14, fontweight='bold')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Feature Distributions\n",
                "\n",
                "#### 2.1 What we're doing\n",
                "Plotting histograms to see how each feature is distributed.\n",
                "\n",
                "#### 2.2 Why important\n",
                "- See if features separate safe/unsafe classes\n",
                "- Identify useful features for ML"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature distributions by class\n",
                "features = [col for col in df.columns if col != 'label']\n",
                "fig, axes = plt.subplots(3, 3, figsize=(14, 12))\n",
                "\n",
                "for ax, col in zip(axes.flatten(), features):\n",
                "    sns.histplot(data=df, x=col, hue='label', ax=ax, kde=True, alpha=0.6)\n",
                "    ax.set_title(f'{col}', fontsize=11)\n",
                "    ax.legend(['Unsafe', 'Safe'])\n",
                "\n",
                "plt.suptitle('Feature Distributions by Safety Label', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Correlation Heatmap\n",
                "\n",
                "#### 2.1 What it shows\n",
                "How features relate to each other and to the target.\n",
                "\n",
                "#### 2.2 Why important\n",
                "- **Positive correlation**: When one goes up, other goes up\n",
                "- **Negative correlation**: When one goes up, other goes down\n",
                "- Helps identify important features for prediction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation heatmap\n",
                "plt.figure(figsize=(10, 8))\n",
                "correlation = df.corr()\n",
                "sns.heatmap(correlation, annot=True, cmap='RdYlBu_r', center=0,\n",
                "            fmt='.2f', square=True, linewidths=0.5)\n",
                "plt.title('Feature Correlations\\n(Red=Positive, Blue=Negative)', \n",
                "          fontsize=12, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Features most correlated with label\n",
                "print(\"\\nüéØ Correlation with Safety Label:\")\n",
                "label_corr = correlation['label'].drop('label').sort_values(key=abs, ascending=False)\n",
                "for feat, corr in label_corr.items():\n",
                "    direction = \"‚Üë\" if corr > 0 else \"‚Üì\"\n",
                "    print(f\"   {feat:18s}: {corr:+.3f} {direction}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üßπ Data Preparation\n",
                "\n",
                "### üîπ Separating Features (X) and Target (y)\n",
                "\n",
                "#### 2.1 What we're doing\n",
                "Splitting data into:\n",
                "- **X (Features)**: The inputs the model sees\n",
                "- **y (Target)**: The answer we want to predict\n",
                "\n",
                "#### 2.2 Why\n",
                "ML algorithms need this format: \"Given X, predict y\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Separate features and target\n",
                "X = df.drop('label', axis=1)  # All columns except label\n",
                "y = df['label']               # Only the label column\n",
                "\n",
                "print(f\"üìä Features (X) shape: {X.shape}\")\n",
                "print(f\"üìä Target (y) shape: {y.shape}\")\n",
                "print(f\"\\nüìã Feature names: {list(X.columns)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Train-Test Split: `train_test_split()`\n",
                "\n",
                "#### 2.1 What it does\n",
                "Randomly splits data into training and testing sets.\n",
                "\n",
                "#### 2.2 Why needed\n",
                "- **Training set**: To teach the model\n",
                "- **Testing set**: To check if it learned well\n",
                "- Like studying (training) then taking an exam (testing)!\n",
                "\n",
                "### ‚öôÔ∏è Arguments Explained\n",
                "\n",
                "| Argument | What | Why | Default |\n",
                "|----------|------|-----|--------|\n",
                "| X, y | Data | Required inputs | - |\n",
                "| test_size | % for testing | 20% is common | 0.25 |\n",
                "| random_state | Seed number | Reproducibility | None |\n",
                "| stratify | Keep class ratio | Important for imbalanced data | None |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split into training and testing sets\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y,\n",
                "    test_size=TEST_SIZE,       # 20% for testing\n",
                "    random_state=RANDOM_STATE, # Same split each run\n",
                "    stratify=y                 # Keep class balance\n",
                ")\n",
                "\n",
                "print(f\"üìä Training set: {X_train.shape[0]} samples ({100-TEST_SIZE*100:.0f}%)\")\n",
                "print(f\"üìä Testing set:  {X_test.shape[0]} samples ({TEST_SIZE*100:.0f}%)\")\n",
                "\n",
                "# Verify class balance maintained\n",
                "print(f\"\\nüìä Training class distribution:\")\n",
                "print(f\"   Safe: {sum(y_train==1)} | Unsafe: {sum(y_train==0)}\")\n",
                "print(f\"üìä Testing class distribution:\")\n",
                "print(f\"   Safe: {sum(y_test==1)} | Unsafe: {sum(y_test==0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Feature Scaling: `StandardScaler`\n",
                "\n",
                "#### 2.1 What it does\n",
                "Transforms features to have mean=0 and std=1.\n",
                "\n",
                "#### 2.2 Why needed\n",
                "Some algorithms work better when features are on same scale.\n",
                "- slope_deg: 0-20\n",
                "- roughness: 0-1\n",
                "- Without scaling, slope_deg dominates!\n",
                "\n",
                "#### 2.3 Formula\n",
                "```\n",
                "scaled = (value - mean) / std\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scale features\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)  # Fit on train, transform\n",
                "X_test_scaled = scaler.transform(X_test)        # Only transform test\n",
                "\n",
                "# Convert back to DataFrame\n",
                "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)\n",
                "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n",
                "\n",
                "print(\"‚úÖ Features scaled to standard normal distribution\")\n",
                "print(\"\\nüìä Scaled training data sample:\")\n",
                "X_train_scaled.head(3).round(3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ü§ñ Task 2: Machine Learning Model\n",
                "\n",
                "### üîπ Random Forest Classifier\n",
                "\n",
                "#### 2.1 What is it?\n",
                "An **ensemble** of many decision trees that \"vote\" together.\n",
                "\n",
                "#### 2.2 Why use it?\n",
                "- Handles non-linear relationships well\n",
                "- Robust to overfitting\n",
                "- Gives feature importance\n",
                "\n",
                "#### 2.3 Real-life analogy\n",
                "Like asking 100 experts and taking majority vote!\n",
                "\n",
                "### ‚öôÔ∏è RandomForestClassifier Arguments\n",
                "\n",
                "| Argument | What | Why | Our Value |\n",
                "|----------|------|-----|-----------|\n",
                "| n_estimators | Number of trees | More = better but slower | 100 |\n",
                "| max_depth | Tree depth limit | Prevents overfitting | 10 |\n",
                "| random_state | Seed | Reproducibility | 42 |\n",
                "| n_jobs | CPU cores | -1 = use all | -1 |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Random Forest\n",
                "model = RandomForestClassifier(\n",
                "    n_estimators=100,       # 100 trees in the forest\n",
                "    max_depth=10,           # Limit tree depth\n",
                "    min_samples_split=5,    # Min samples to split\n",
                "    min_samples_leaf=2,     # Min samples in leaf\n",
                "    random_state=RANDOM_STATE,\n",
                "    n_jobs=-1               # Use all CPU cores\n",
                ")\n",
                "\n",
                "print(\"üå≤ Random Forest Classifier initialized\")\n",
                "print(f\"   Trees: {model.n_estimators}\")\n",
                "print(f\"   Max depth: {model.max_depth}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Training the Model: `model.fit()`\n",
                "\n",
                "#### 2.1 What it does\n",
                "\"Teaches\" the model by finding patterns in training data.\n",
                "\n",
                "#### 2.2 How it works internally\n",
                "1. Creates 100 decision trees\n",
                "2. Each tree uses random subset of data\n",
                "3. Each tree learns different patterns\n",
                "4. Stores all trees for later voting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train the model\n",
                "print(\"üîÑ Training Random Forest...\")\n",
                "model.fit(X_train_scaled, y_train)\n",
                "print(\"‚úÖ Model trained successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Making Predictions\n",
                "\n",
                "#### 2.1 `model.predict()`\n",
                "Returns class labels (0 or 1).\n",
                "\n",
                "#### 2.2 `model.predict_proba()`\n",
                "Returns probabilities for each class."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions\n",
                "y_pred = model.predict(X_test_scaled)\n",
                "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
                "\n",
                "print(f\"üìä Predictions made for {len(y_pred)} test samples\")\n",
                "print(f\"\\nüìã Sample predictions:\")\n",
                "print(f\"   Actual:    {list(y_test[:5].values)}\")\n",
                "print(f\"   Predicted: {list(y_pred[:5])}\")\n",
                "print(f\"   Probability: {[f'{p:.2f}' for p in y_pred_proba[:5]]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Model Evaluation Metrics\n",
                "\n",
                "#### Why Accuracy Alone is Insufficient?\n",
                "\n",
                "In **safety-critical systems**:\n",
                "\n",
                "| Mistake Type | What Happens | Impact |\n",
                "|--------------|--------------|--------|\n",
                "| FALSE NEGATIVE | Predict \"safe\" when UNSAFE | üî¥ CRASH! Dangerous! |\n",
                "| FALSE POSITIVE | Predict \"unsafe\" when SAFE | üü° Missed opportunity |\n",
                "\n",
                "**Accuracy can be misleading!**\n",
                "- If 90% zones are safe, always predicting \"safe\" = 90% accuracy\n",
                "- But we miss ALL dangerous zones!\n",
                "\n",
                "#### Key Metrics\n",
                "- **Precision**: When we say \"safe\", how often correct?\n",
                "- **Recall**: Of all safe zones, how many did we find?\n",
                "- **F1-Score**: Balance of precision and recall\n",
                "- **ROC-AUC**: Overall discrimination ability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate metrics\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "precision = precision_score(y_test, y_pred)\n",
                "recall = recall_score(y_test, y_pred)\n",
                "f1 = f1_score(y_test, y_pred)\n",
                "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"üìè MODEL PERFORMANCE METRICS\")\n",
                "print(\"=\"*50)\n",
                "print(f\"\\nüìä Accuracy:  {accuracy:.4f} ({accuracy*100:.1f}%)\")\n",
                "print(f\"üìä Precision: {precision:.4f} ({precision*100:.1f}%)\")\n",
                "print(f\"üìä Recall:    {recall:.4f} ({recall*100:.1f}%)\")\n",
                "print(f\"üìä F1-Score:  {f1:.4f} ({f1*100:.1f}%)\")\n",
                "print(f\"üìä ROC-AUC:   {roc_auc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Confusion Matrix\n",
                "\n",
                "#### 2.1 What it shows\n",
                "A table comparing actual vs predicted labels.\n",
                "\n",
                "```\n",
                "                  PREDICTED\n",
                "                 Safe   Unsafe\n",
                "        Safe      TP      FN     ‚Üê Actual Safe\n",
                "ACTUAL\n",
                "        Unsafe    FP      TN     ‚Üê Actual Unsafe\n",
                "```\n",
                "\n",
                "- **TP**: True Positive (correctly predicted safe)\n",
                "- **TN**: True Negative (correctly predicted unsafe)\n",
                "- **FP**: False Positive (wrongly predicted safe)\n",
                "- **FN**: False Negative (wrongly predicted unsafe) ‚Üê DANGEROUS!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
                "            xticklabels=['UNSAFE', 'SAFE'],\n",
                "            yticklabels=['UNSAFE', 'SAFE'])\n",
                "plt.xlabel('Predicted Label', fontsize=12)\n",
                "plt.ylabel('Actual Label', fontsize=12)\n",
                "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nüìä Breakdown:\")\n",
                "print(f\"   True Negatives (correct unsafe):  {cm[0,0]}\")\n",
                "print(f\"   False Positives (wrong safe):     {cm[0,1]}\")\n",
                "print(f\"   False Negatives (wrong unsafe):   {cm[1,0]} ‚ö†Ô∏è DANGEROUS\")\n",
                "print(f\"   True Positives (correct safe):    {cm[1,1]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ ROC Curve\n",
                "\n",
                "#### 2.1 What it shows\n",
                "Trade-off between True Positive Rate and False Positive Rate at different thresholds.\n",
                "\n",
                "#### 2.2 How to read it\n",
                "- **Diagonal line**: Random guessing (AUC=0.5)\n",
                "- **Closer to top-left**: Better model\n",
                "- **AUC > 0.9**: Excellent!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ROC Curve\n",
                "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
                "plt.plot([0, 1], [0, 1], 'r--', linewidth=1, label='Random Guess')\n",
                "plt.fill_between(fpr, tpr, alpha=0.3)\n",
                "plt.xlabel('False Positive Rate', fontsize=12)\n",
                "plt.ylabel('True Positive Rate (Recall)', fontsize=12)\n",
                "plt.title('ROC Curve\\n(Closer to top-left = Better)', fontsize=14, fontweight='bold')\n",
                "plt.legend(loc='lower right')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Feature Importance\n",
                "\n",
                "#### 2.1 What it shows\n",
                "Which features the model relies on most for predictions.\n",
                "\n",
                "#### 2.2 Why useful\n",
                "- Understand what drives safety decisions\n",
                "- Identify key terrain factors\n",
                "- Simplify model if needed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Importance\n",
                "importances = pd.DataFrame({\n",
                "    'Feature': X.columns,\n",
                "    'Importance': model.feature_importances_\n",
                "}).sort_values('Importance', ascending=False)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "colors = plt.cm.RdYlGn(importances['Importance'] / importances['Importance'].max())\n",
                "plt.barh(importances['Feature'], importances['Importance'], color=colors)\n",
                "plt.xlabel('Importance Score', fontsize=12)\n",
                "plt.ylabel('Feature', fontsize=12)\n",
                "plt.title('Feature Importance for Landing Zone Safety', fontsize=14, fontweight='bold')\n",
                "plt.gca().invert_yaxis()\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nüåü Feature Importance Ranking:\")\n",
                "for _, row in importances.iterrows():\n",
                "    bar = '‚ñà' * int(row['Importance'] * 40)\n",
                "    print(f\"   {row['Feature']:18s} {bar} {row['Importance']:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üó∫Ô∏è Task 3: Spatial Safety Analysis & Visualization\n",
                "\n",
                "### üîπ Creating Safety Heatmap\n",
                "\n",
                "#### 2.1 What we're doing\n",
                "Visualizing safety predictions as a color-coded grid.\n",
                "\n",
                "#### 2.2 Why\n",
                "Maps are easier to understand than numbers!\n",
                "- üü¢ Green = Safe to land\n",
                "- üü° Yellow = Caution\n",
                "- üî¥ Red = Avoid"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get predictions for all data\n",
                "X_all_scaled = scaler.transform(X)\n",
                "all_predictions = model.predict(X_all_scaled)\n",
                "all_probabilities = model.predict_proba(X_all_scaled)[:, 1]\n",
                "\n",
                "# Create grid\n",
                "grid_size = int(np.ceil(np.sqrt(len(df))))\n",
                "n_cells = grid_size * grid_size\n",
                "probs_padded = np.zeros(n_cells)\n",
                "probs_padded[:len(all_probabilities)] = all_probabilities\n",
                "heatmap_data = probs_padded.reshape(grid_size, grid_size)\n",
                "\n",
                "print(f\"üìä Grid Size: {grid_size} √ó {grid_size}\")\n",
                "print(f\"üìä Total Zones: {len(df)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create heatmap\n",
                "plt.figure(figsize=(12, 10))\n",
                "im = plt.imshow(heatmap_data, cmap='RdYlGn', vmin=0, vmax=1, aspect='equal')\n",
                "cbar = plt.colorbar(im, label='Safety Probability')\n",
                "cbar.ax.set_ylabel('Safety Score\\n(Green=Safe, Red=Unsafe)', fontsize=10)\n",
                "plt.xlabel('Grid Column (East ‚Üí)', fontsize=12)\n",
                "plt.ylabel('Grid Row (North ‚Üë)', fontsize=12)\n",
                "plt.title('üõ¨ Landing Zone Safety Heatmap', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Zone statistics\n",
                "print(\"\\nüìä Zone Distribution by Safety Level:\")\n",
                "high = np.sum(all_probabilities > 0.7)\n",
                "medium = np.sum((all_probabilities >= 0.3) & (all_probabilities <= 0.7))\n",
                "low = np.sum(all_probabilities < 0.3)\n",
                "print(f\"   üü¢ HIGH SAFETY (>70%):     {high} zones ({100*high/len(df):.1f}%)\")\n",
                "print(f\"   üü° MEDIUM SAFETY (30-70%): {medium} zones ({100*medium/len(df):.1f}%)\")\n",
                "print(f\"   üî¥ LOW SAFETY (<30%):      {low} zones ({100*low/len(df):.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ‚úàÔ∏è Task 4: Drone Autonomy Interpretation\n",
                "\n",
                "### üîπ Landing Strategy Recommendations\n",
                "\n",
                "Converting AI predictions into actionable decisions for autonomous drones."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create zone rankings\n",
                "zone_rankings = pd.DataFrame({\n",
                "    'Zone_ID': range(len(df)),\n",
                "    'Safety_Score': all_probabilities,\n",
                "    'Confidence': np.abs(all_probabilities - 0.5) * 2\n",
                "}).sort_values('Safety_Score', ascending=False)\n",
                "\n",
                "print(\"üéØ LANDING STRATEGY RECOMMENDATIONS\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "# Top 5 safest zones\n",
                "print(\"\\nüü¢ TOP 5 RECOMMENDED LANDING ZONES:\")\n",
                "for _, row in zone_rankings.head(5).iterrows():\n",
                "    status = \"‚úÖ CLEAR\" if row['Safety_Score'] > 0.8 else \"‚ö†Ô∏è CAUTION\"\n",
                "    print(f\"   Zone {int(row['Zone_ID']):4d}: Safety {row['Safety_Score']:.1%} | {status}\")\n",
                "\n",
                "# Bottom 5 (avoid)\n",
                "print(\"\\nüî¥ ZONES TO AVOID:\")\n",
                "for _, row in zone_rankings.tail(5).iloc[::-1].iterrows():\n",
                "    print(f\"   Zone {int(row['Zone_ID']):4d}: Safety {row['Safety_Score']:.1%} | ‚ùå AVOID\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Decision Framework\n",
                "\n",
                "| Safety Score | Confidence | Action |\n",
                "|--------------|------------|--------|\n",
                "| > 80% | > 70% | ‚úÖ AUTO-LAND |\n",
                "| > 80% | < 70% | ‚ö†Ô∏è REQUEST CONFIRMATION |\n",
                "| 50-80% | Any | üîç SECONDARY SCAN |\n",
                "| 30-50% | Any | üîÑ FIND ALTERNATIVE |\n",
                "| < 30% | Any | ‚ùå ABORT & RELOCATE |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nüìã AUTONOMY DECISION FRAMEWORK:\")\n",
                "print(\"\"\"\n",
                "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
                "‚îÇ  SAFETY SCORE  ‚îÇ  CONFIDENCE  ‚îÇ  ACTION                ‚îÇ\n",
                "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
                "‚îÇ   > 80%        ‚îÇ    > 70%     ‚îÇ  ‚úÖ AUTO-LAND          ‚îÇ\n",
                "‚îÇ   > 80%        ‚îÇ    < 70%     ‚îÇ  ‚ö†Ô∏è  REQUEST CONFIRM   ‚îÇ\n",
                "‚îÇ   50-80%       ‚îÇ    Any       ‚îÇ  üîç SECONDARY SCAN     ‚îÇ\n",
                "‚îÇ   30-50%       ‚îÇ    Any       ‚îÇ  üîÑ FIND ALTERNATIVE   ‚îÇ\n",
                "‚îÇ   < 30%        ‚îÇ    Any       ‚îÇ  ‚ùå ABORT & RELOCATE   ‚îÇ\n",
                "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
                "\"\"\")\n",
                "\n",
                "print(\"üîÑ FALLBACK BEHAVIORS:\")\n",
                "print(\"\"\"\n",
                "1. IF no safe zones ‚Üí Expand search radius\n",
                "2. IF battery critical ‚Üí Find least unsafe zone + emergency landing\n",
                "3. IF conflicting data ‚Üí Hover and re-scan\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## üîç Task 5: Reflection & Limitations\n",
                "\n",
                "### Current Dataset Limitations\n",
                "\n",
                "| Limitation | Issue | Solution |\n",
                "|------------|-------|----------|\n",
                "| No GPS | Can't map to real world | Add lat/long |\n",
                "| Static | No time/weather changes | Add timestamps |\n",
                "| Single view | May miss obstacles | Multi-view fusion |\n",
                "| Simulated | Not real sensor data | Collect real data |\n",
                "| Binary | Only safe/unsafe | Add gradations |\n",
                "\n",
                "### Proposed Improvements\n",
                "\n",
                "1. **Real-time perception** - Live camera analysis\n",
                "2. **Multi-sensor fusion** - RGB + LiDAR + radar\n",
                "3. **Weather integration** - Wind, visibility\n",
                "4. **Historical data** - Previous landing outcomes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*60)\n",
                "print(\"üîç TASK 5: REFLECTION & LIMITATIONS\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "print(\"\"\"\n",
                "üìö CURRENT LIMITATIONS:\n",
                "   1. No real GPS coordinates\n",
                "   2. Static snapshot (no temporal changes)\n",
                "   3. Single camera viewpoint\n",
                "   4. Simulated/synthetic data\n",
                "   5. Binary labels only\n",
                "\n",
                "üöÄ PROPOSED IMPROVEMENTS:\n",
                "   1. Real-time camera feed analysis\n",
                "   2. Multi-sensor fusion (LiDAR + radar)\n",
                "   3. Weather API integration\n",
                "   4. Historical landing outcomes\n",
                "   5. Continuous safety scores\n",
                "\"\"\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ CAPSTONE COMPLETE!\")\n",
                "print(\"=\"*60)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}