{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Robust Clustering Evaluation Pipeline\n",
                "\n",
                "### üß© Problem Statement\n",
                "- **What**: We need to segment 5000 B2B SaaS accounts into meaningful groups based on usage behavior (e.g., logins, feature adoption).\n",
                "- **Why**: To enable targeted marketing (churn prevention, upselling) without having pre-existing labels (no ground truth).\n",
                "- **Relevance**: In the real world, data is often unlabeled (\"Unsupervised Learning\"). We need a robust way to find patterns that aren't just random noise.\n",
                "\n",
                "### ü™ú Steps to Solve the Problem\n",
                "1.  **Synthetic Data Generation**: Create a realistic dataset with missing values to simulate real-world messiness.\n",
                "2.  **Preprocessing**: Build a strictly reproducible pipeline to handle missing data (Imputation) and scale features (Standardization).\n",
                "3.  **Model Comparison**: Train `KMeans`, `MiniBatchKMeans`, and `GMM` across different cluster counts (K=3..6).\n",
                "4.  **Evaluation**: Use **Silhouette Score**, **Calinski-Harabasz Index**, and **Inertia** to find the best K.\n",
                "5.  **Stability Analysis**: Verify the chosen model's robustness by running it with multiple random seeds and checking the **Adjusted Rand Index (ARI)**.\n",
                "6.  **Interpretation**: Translate mathematical clusters into business personas.\n",
                "\n",
                "### üéØ Expected Output\n",
                "- A recommendation on the optimal number of clusters (K).\n",
                "- A stability score confirming if the clusters are reliable.\n",
                "- Business profiles for each segment (e.g. \"Champions\", \"At-Risk\")."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Imports Explanation\n",
                "#### 2.1 What the line does\n",
                "Imports necessary libraries for data manipulation, visualization, machine learning, and metrics.\n",
                "\n",
                "#### 2.2 Why it is used\n",
                "- `numpy` & `pandas`: Foundation for data structures.\n",
                "- `sklearn`: The industry standard library for traditional ML algorithms in Python.\n",
                "- `matplotlib` & `seaborn`: For visualizing the metric trends.\n",
                "\n",
                "#### 2.3 When to use it\n",
                "At the start of every Data Science project.\n",
                "\n",
                "\n",
                "#### 2.5 How to use it\n",
                "Standard python import syntax.\n",
                "\n",
                "#### 2.6 How it works internally\n",
                "Loads the compiled C/C++ extensions (for numpy/sklearn) into memory for fast execution."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.datasets import make_blobs\n",
                "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
                "from sklearn.mixture import GaussianMixture\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.metrics import silhouette_score, calinski_harabasz_score, adjusted_rand_score\n",
                "import warnings\n",
                "\n",
                "warnings.filterwarnings('ignore') # Clean up output for teaching"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Data Generation Function\n",
                "\n",
                "#### ‚öôÔ∏è Function Arguments Explanation: `make_blobs`\n",
                "- `n_samples`: Total data points (5000). More samples = more stable clusters.\n",
                "- `n_features`: Number of columns (12). Represents metrics like \"Logins\", \"PageViews\", etc.\n",
                "- `centers`: The true number of clusters to generate (5). In real life, we wouldn't know this.\n",
                "- `cluster_std`: How spread out each blob is. Higher = harder to cluster.\n",
                "- `random_state`: Seed for reproducibility.\n",
                "\n",
                "#### 2.1 What the code does\n",
                "Generates a synthetic matrix of data `X` and creates artificial missing values (NaNs) to mimic real-world dirty data.\n",
                "\n",
                "#### 2.2 Why it is used\n",
                "We don't have access to the company's internal database, so we simulate it to test our pipeline.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_saas_data(n_samples=5000, n_features=12, random_state=42):\n",
                "    \"\"\"\n",
                "    Generates synthetic B2B SaaS data.\n",
                "    Simulates features like Logins, FeatureAdoption, SupportInteractions, etc.\n",
                "    \"\"\"\n",
                "    # Generate clean blobs\n",
                "    X, y = make_blobs(n_samples=n_samples, n_features=n_features, centers=5, \n",
                "                      cluster_std=2.5, random_state=random_state)\n",
                "    \n",
                "    # Introduce some missing values (Dirty Data Simulation)\n",
                "    rng = np.random.RandomState(random_state)\n",
                "    mask = rng.rand(n_samples, n_features) < 0.05 # 5% probability of being missing\n",
                "    X_missing = X.copy()\n",
                "    X_missing[mask] = np.nan\n",
                "    \n",
                "    feature_names = [f'Feature_{i+1}' for i in range(n_features)]\n",
                "    return X_missing, feature_names"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Compare Models Function\n",
                "\n",
                "This is the core logic engine.\n",
                "\n",
                "#### ‚öôÔ∏è Important Concepts\n",
                "1. **Pipeline**: chaining `SimpleImputer` -> `StandardScaler`. We do this *outside* the loop here to speed up calculation, but typically it should be part of the prediction flow.\n",
                "2. **Inertia**: Sum of squared distances to closest centroid. Lower is better (more compact).\n",
                "3. **Silhouette Score**: How well separated clusters are. Ranges [-1, 1]. Higher is better.\n",
                "4. **Calinski-Harabasz**: Ratio of dispersion. Higher is better."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compare_models(X, k_range, output_dir):\n",
                "    results = []\n",
                "    \n",
                "    # Preprocess once for efficiency in this comparison loop\n",
                "    preprocessor = Pipeline([\n",
                "        ('imputer', SimpleImputer(strategy='mean')), # Fill NaNs with column mean\n",
                "        ('scaler', StandardScaler())                 # Scale to mean=0, std=1\n",
                "    ])\n",
                "    X_processed = preprocessor.fit_transform(X)\n",
                "    \n",
                "    best_score = -1\n",
                "    best_model_config = None\n",
                "\n",
                "    models_to_test = ['KMeans', 'MiniBatchKMeans', 'GMM']\n",
                "    \n",
                "    print(\"Starting Model Comparison...\")\n",
                "    \n",
                "    for k in k_range:\n",
                "        for name in models_to_test:\n",
                "            # Initialize Model\n",
                "            if name == 'KMeans':\n",
                "                model = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
                "            elif name == 'MiniBatchKMeans':\n",
                "                model = MiniBatchKMeans(n_clusters=k, random_state=42, n_init=10)\n",
                "            else: # GMM\n",
                "                model = GaussianMixture(n_components=k, random_state=42)\n",
                "            \n",
                "            # Fit Model\n",
                "            model.fit(X_processed)\n",
                "            \n",
                "            # Get Labels & Metrics\n",
                "            if name == 'GMM':\n",
                "                labels = model.predict(X_processed)\n",
                "                inertia = np.nan # GMM minimizes log-likelihood, not inertia\n",
                "            else:\n",
                "                labels = model.labels_\n",
                "                inertia = model.inertia_\n",
                "            \n",
                "            # Calculate Silhouette (Sampled for speed if N is huge)\n",
                "            sil_score = silhouette_score(X_processed, labels, sample_size=1000, random_state=42)\n",
                "            ch_score = calinski_harabasz_score(X_processed, labels)\n",
                "            \n",
                "            results.append({\n",
                "                'Model': name,\n",
                "                'K': k,\n",
                "                'Inertia': inertia,\n",
                "                'Silhouette': sil_score,\n",
                "                'Calinski_Harabasz': ch_score\n",
                "            })\n",
                "            \n",
                "            # Track Winner\n",
                "            if sil_score > best_score:\n",
                "                best_score = sil_score\n",
                "                best_model_config = (name, k)\n",
                "                \n",
                "    return pd.DataFrame(results), best_model_config"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Stability Analysis Function\n",
                "\n",
                "#### 2.1 What the code does\n",
                "Runs the *best* model configuration 5 times with DIFFERENT random seeds and compares the results.\n",
                "\n",
                "#### 2.2 Why it is used\n",
                "**Crucial Step**: In unsupervised learning, a \"good\" score might be a fluke of initialization. If we run it again tomorrow, will we get the same customer segments?\n",
                "- If **ARI (Adjusted Rand Index)** is near 1.0: Stable. Safe to use.\n",
                "- If **ARI** is near 0.0: Unstable. Random noise. Do NOT use.\n",
                "\n",
                "#### 3.5 How to use `adjusted_rand_score`\n",
                "`score = adjusted_rand_score(labels_1, labels_2)` compares two lists of cluster assignments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def stability_analysis(X, model_name, k):\n",
                "    print(f\"\\nRunning Stability Analysis for {model_name} with K={k}...\")\n",
                "    \n",
                "    # Preprocess again (simulating fresh runs)\n",
                "    preprocessor = Pipeline([\n",
                "        ('imputer', SimpleImputer(strategy='mean')),\n",
                "        ('scaler', StandardScaler())\n",
                "    ])\n",
                "    X_processed = preprocessor.fit_transform(X)\n",
                "    \n",
                "    seeds = [42, 1, 2, 3, 4]\n",
                "    labels_list = []\n",
                "    \n",
                "    for seed in seeds:\n",
                "        if model_name == 'KMeans':\n",
                "            model = KMeans(n_clusters=k, random_state=seed, n_init=10)\n",
                "        elif model_name == 'MiniBatchKMeans':\n",
                "            model = MiniBatchKMeans(n_clusters=k, random_state=seed, n_init=10)\n",
                "        else:\n",
                "            model = GaussianMixture(n_components=k, random_state=seed)\n",
                "        \n",
                "        if model_name == 'GMM':\n",
                "            labels = model.fit_predict(X_processed)\n",
                "        else:\n",
                "            model.fit(X_processed)\n",
                "            labels = model.labels_\n",
                "        labels_list.append(labels)\n",
                "    \n",
                "    # Pairwise comparison\n",
                "    ari_scores = []\n",
                "    for i in range(len(seeds)):\n",
                "        for j in range(i + 1, len(seeds)):\n",
                "            score = adjusted_rand_score(labels_list[i], labels_list[j])\n",
                "            ari_scores.append(score)\n",
                "            \n",
                "    avg_stability = np.mean(ari_scores)\n",
                "    return avg_stability"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üîπ Main Execution\n",
                "\n",
                "1. Generate Data.\n",
                "2. Compare all models.\n",
                "3. Pick the winner.\n",
                "4. Check winner's stability.\n",
                "5. Print Business Conclusion."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Generate Data\n",
                "X, feature_names = generate_saas_data()\n",
                "print(f\"Data Generated: {X.shape}\")\n",
                "\n",
                "# 2. Compare Models\n",
                "k_range = [3, 4, 5, 6]\n",
                "results_df, best_config = compare_models(X, k_range, output_dir=None)\n",
                "\n",
                "# Display Top Results\n",
                "print(\"\\nModel Comparison Metrics:\")\n",
                "display(results_df.sort_values(by='Silhouette', ascending=False).head())\n",
                "\n",
                "# 3. Best Model Info\n",
                "best_model_name, best_k = best_config\n",
                "print(f\"\\nüèÜ Best Configuration: {best_model_name} with K={best_k}\")\n",
                "\n",
                "# 4. Check Stability\n",
                "stability = stability_analysis(X, best_model_name, best_k)\n",
                "print(f\"\\n‚öì Average Stability Score (ARI): {stability:.4f}\")\n",
                "if stability > 0.9:\n",
                "    print(\"‚úÖ Result: Extremely Robust Clusters.\")\n",
                "elif stability > 0.75:\n",
                "    print(\"‚úÖ Result: Stable Clusters.\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Result: Unstable Clusters. Do not deploy.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}