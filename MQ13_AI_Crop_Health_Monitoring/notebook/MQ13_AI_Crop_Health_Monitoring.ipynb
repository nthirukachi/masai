{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üåæ AI-Based Crop Health Monitoring Using Drone Multispectral Data üöÅ\n",
                "\n",
                "## üß© Problem Statement\n",
                "\n",
                "### What Problem Are We Solving?\n",
                "\n",
                "Imagine you are a **farmer** with a HUGE farm - so big that you can't walk around and check every single plant! Some plants might be **sick** (stressed) - they might not be getting enough water, bugs might be eating them, or the soil might not be good.\n",
                "\n",
                "**Solution:** We use a **flying robot called a DRONE** üöÅ that flies over the farm and takes special photos. Then we use **AI (Artificial Intelligence)** ü§ñ to analyze these photos and tell which plants are healthy and which are stressed.\n",
                "\n",
                "### Real-Life Analogy\n",
                "\n",
                "| Human Health | Plant Health |\n",
                "|-------------|------------|\n",
                "| Doctor uses thermometer üå°Ô∏è | Drone uses special camera üì∏ |\n",
                "| Doctor checks blood pressure | Drone checks plant color/moisture |\n",
                "| Doctor says \"Take medicine!\" | AI says \"Water this area!\" |\n",
                "\n",
                "---\n",
                "\n",
                "## ü™ú Steps to Solve the Problem\n",
                "\n",
                "1. **Load and explore** the dataset (understand what we have)\n",
                "2. **Prepare data** for machine learning (clean and split)\n",
                "3. **Train 5 ML models** and compare them\n",
                "4. **Create a stress map** showing healthy vs stressed areas\n",
                "5. **Recommend drone flight paths** for inspection\n",
                "\n",
                "---\n",
                "\n",
                "## üéØ Expected Output\n",
                "\n",
                "- Model comparison table showing which algorithm works best\n",
                "- A colorful heatmap showing stressed areas in red, healthy in green\n",
                "- Priority list of zones for drone inspection"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üì¶ Section 1: Importing Libraries\n",
                "\n",
                "### üîπ What are libraries?\n",
                "\n",
                "Libraries are like **toolboxes** that contain ready-made tools. Instead of building everything from scratch, we use tools others have created.\n",
                "\n",
                "**Real-Life Analogy:** Like using a calculator instead of doing math by hand!\n",
                "\n",
                "### Libraries we'll use:\n",
                "\n",
                "| Library | What it does | Like in real life |\n",
                "|---------|--------------|-------------------|\n",
                "| `pandas` | Handles data tables | Excel spreadsheet |\n",
                "| `numpy` | Math operations | Calculator |\n",
                "| `matplotlib` | Creates charts | Drawing with colors |\n",
                "| `seaborn` | Prettier charts | Professional artist |\n",
                "| `sklearn` | Machine learning | AI brain |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# IMPORTING LIBRARIES\n",
                "# =============================================================================\n",
                "\n",
                "# pandas: For handling data like Excel spreadsheets\n",
                "import pandas as pd\n",
                "\n",
                "# numpy: For fast math operations\n",
                "import numpy as np\n",
                "\n",
                "# matplotlib: For creating charts and plots\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# seaborn: For beautiful statistical visualizations\n",
                "import seaborn as sns\n",
                "\n",
                "# Ignore warnings to keep output clean\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"‚úÖ All libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Importing Machine Learning Tools from scikit-learn\n",
                "\n",
                "#### 2.1 What does each import do?\n",
                "\n",
                "| Import | Purpose | Simple Explanation |\n",
                "|--------|---------|-------------------|\n",
                "| `train_test_split` | Splits data into training and testing | Like splitting flashcards for study vs exam |\n",
                "| `StandardScaler` | Makes all features same scale | Converting inches and kg to same unit |\n",
                "| `LabelEncoder` | Converts text labels to numbers | \"Healthy\"‚Üí0, \"Stressed\"‚Üí1 |\n",
                "\n",
                "#### 2.2 Why do we need these?\n",
                "- **train_test_split**: We can't test students on questions they already studied!\n",
                "- **StandardScaler**: Comparing height (180cm) with weight (70kg) is unfair - different scales!\n",
                "- **LabelEncoder**: Computers understand numbers, not words"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# IMPORTING MACHINE LEARNING TOOLS\n",
                "# =============================================================================\n",
                "\n",
                "# For splitting data into train/test sets\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# For scaling features to same range\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "# For converting text labels to numbers\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "print(\"‚úÖ ML preprocessing tools imported!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Importing Classification Models\n",
                "\n",
                "We will compare **5 different AI models** to see which one works best for detecting crop stress.\n",
                "\n",
                "| Model | How it works | Real-Life Analogy |\n",
                "|-------|--------------|-------------------|\n",
                "| **Logistic Regression** | Draws a straight line to separate classes | Like sorting apples vs oranges with a ruler |\n",
                "| **Decision Tree** | Makes yes/no decisions like a flowchart | Like 20 Questions game |\n",
                "| **Random Forest** | Many trees voting together | Asking 100 people and going with majority |\n",
                "| **SVM** | Finds the best boundary between classes | Drawing the widest possible road between groups |\n",
                "| **KNN** | Looks at nearest neighbors | \"You are who your friends are\" |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# IMPORTING CLASSIFICATION MODELS\n",
                "# =============================================================================\n",
                "\n",
                "# Model 1: Logistic Regression - Simple, fast, interpretable\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "\n",
                "# Model 2: Decision Tree - Easy to understand flowchart\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "\n",
                "# Model 3: Random Forest - Many trees voting together\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "\n",
                "# Model 4: Support Vector Machine - Finds best boundary\n",
                "from sklearn.svm import SVC\n",
                "\n",
                "# Model 5: K-Nearest Neighbors - Looks at neighbors\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "\n",
                "print(\"‚úÖ All 5 classification models imported!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Importing Evaluation Metrics\n",
                "\n",
                "How do we know if our AI is good? We use **metrics** - like grades for AI!\n",
                "\n",
                "| Metric | What it measures | Simple Explanation |\n",
                "|--------|-----------------|-------------------|\n",
                "| **Accuracy** | Overall correctness | % of correct answers |\n",
                "| **Precision** | When AI says \"Stressed\", how often is it right? | Don't cry wolf if not a wolf |\n",
                "| **Recall** | Of actual stressed plants, how many did AI find? | Don't miss any wolves |\n",
                "| **F1-Score** | Balance of precision and recall | Harmonic mean of both |\n",
                "| **ROC-AUC** | Overall ranking quality | How good at sorting |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# IMPORTING EVALUATION METRICS\n",
                "# =============================================================================\n",
                "\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score,      # Overall correct %\n",
                "    precision_score,     # When I say yes, am I right?\n",
                "    recall_score,        # Did I find all the yes cases?\n",
                "    f1_score,           # Balance of precision and recall\n",
                "    roc_auc_score,      # Overall ranking quality\n",
                "    confusion_matrix,   # Table showing right/wrong predictions\n",
                "    classification_report  # Detailed summary\n",
                ")\n",
                "\n",
                "# For file handling\n",
                "import os\n",
                "\n",
                "print(\"‚úÖ Evaluation metrics imported!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìä TASK 1: DATA UNDERSTANDING\n",
                "\n",
                "### üîπ Loading the Dataset\n",
                "\n",
                "#### 2.1 What is the dataset?\n",
                "Our dataset contains measurements taken by a drone flying over a farm. Each row represents one small area (grid cell) of the field.\n",
                "\n",
                "#### 2.2 Why is this important?\n",
                "This data tells us HOW HEALTHY each area of the farm is using special colors of light that humans can't see!\n",
                "\n",
                "#### 2.3 Understanding the Features (Columns)\n",
                "\n",
                "| Feature | What it measures | Simple Explanation |\n",
                "|---------|-----------------|-------------------|\n",
                "| `ndvi_mean` | Plant greenness | How green and alive |\n",
                "| `gndvi` | Green-based NDVI | Another greenness measure |\n",
                "| `savi` | Vegetation ignoring soil | Plant health without dirt |\n",
                "| `evi` | Enhanced vegetation | Better for dense crops |\n",
                "| `moisture_index` | Water content | Is plant thirsty? |\n",
                "| `canopy_density` | Leaf coverage | How many leaves cover ground |\n",
                "| `grid_x, grid_y` | Location | Where in the field |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# LOADING THE DATASET\n",
                "# =============================================================================\n",
                "\n",
                "print(\"üìä TASK 1: DATA UNDERSTANDING\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Load data from local CSV file\n",
                "# pd.read_csv() reads a comma-separated file into a DataFrame (table)\n",
                "df = pd.read_csv(\"data/crop_health_data.csv\")\n",
                "\n",
                "print(f\"‚úÖ Dataset loaded successfully!\")\n",
                "print(f\"\\nüìã Dataset Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
                "print(f\"   ‚Ä¢ Each row = one grid cell (small area) in the field\")\n",
                "print(f\"   ‚Ä¢ Each column = one measurement taken by the drone\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Exploring the Data Structure\n",
                "\n",
                "#### 2.1 What does `df.columns` do?\n",
                "Lists all the column names in our dataset.\n",
                "\n",
                "#### 2.2 Why do we need this?\n",
                "To understand what measurements we have before building models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# EXPLORING COLUMNS\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\nüìä All Columns in our Dataset:\")\n",
                "print(\"-\" * 40)\n",
                "for i, col in enumerate(df.columns, 1):\n",
                "    print(f\"   {i:2}. {col}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Viewing First Few Rows\n",
                "\n",
                "#### 2.1 What does `df.head()` do?\n",
                "Shows the first 5 rows of data (you can pass a number to show more/less).\n",
                "\n",
                "#### 2.2 Why is this useful?\n",
                "Quick visual check to see what the actual data values look like."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# VIEWING FIRST 5 ROWS\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\nüîç First 5 rows of our dataset:\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Statistical Summary\n",
                "\n",
                "#### 2.1 What does `df.describe()` do?\n",
                "Calculates statistics like mean, min, max, standard deviation for each column.\n",
                "\n",
                "#### 2.2 Why do we need statistics?\n",
                "- To understand the RANGE of values\n",
                "- To spot OUTLIERS (unusual values)\n",
                "- To know if SCALING is needed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# STATISTICAL SUMMARY\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\nüìà Statistical Summary:\")\n",
                "df.describe().round(3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Checking for Missing Values\n",
                "\n",
                "#### 2.1 What are missing values?\n",
                "Empty cells in our data - like unanswered questions on a test.\n",
                "\n",
                "#### 2.2 Why is this a problem?\n",
                "ML models can crash or give wrong results with missing data!\n",
                "\n",
                "#### 2.3 How do we check?\n",
                "`df.isnull().sum()` counts how many missing values in each column."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# CHECKING FOR MISSING VALUES\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\nüîé Missing Values Check:\")\n",
                "missing = df.isnull().sum().sum()\n",
                "\n",
                "if missing == 0:\n",
                "    print(\"   ‚úÖ No missing values found! Data is complete.\")\n",
                "else:\n",
                "    print(f\"   ‚ö†Ô∏è Found {missing} missing values. Need cleaning!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Understanding the Target Variable\n",
                "\n",
                "#### 2.1 What is the target variable?\n",
                "The column we want to PREDICT - `crop_health_label` (Healthy or Stressed).\n",
                "\n",
                "#### 2.2 Why check the distribution?\n",
                "- **Balanced**: ~50% healthy, ~50% stressed ‚Üí easy to train\n",
                "- **Imbalanced**: 99% healthy, 1% stressed ‚Üí model might just say \"healthy\" always!\n",
                "\n",
                "#### 2.3 What does `value_counts()` do?\n",
                "Counts how many of each unique value exists."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# TARGET VARIABLE DISTRIBUTION\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\nüéØ Target Variable Distribution:\")\n",
                "print(\"-\" * 40)\n",
                "\n",
                "target_counts = df['crop_health_label'].value_counts()\n",
                "for label, count in target_counts.items():\n",
                "    percentage = count / len(df) * 100\n",
                "    emoji = \"üü¢\" if label == \"Healthy\" else \"üî¥\"\n",
                "    print(f\"   {emoji} {label}: {count} samples ({percentage:.1f}%)\")\n",
                "\n",
                "# Visualize the distribution\n",
                "plt.figure(figsize=(8, 5))\n",
                "colors = ['#2ecc71', '#e74c3c']  # Green for healthy, Red for stressed\n",
                "target_counts.plot(kind='bar', color=colors, edgecolor='black')\n",
                "plt.title('üéØ Distribution of Crop Health Labels', fontsize=14)\n",
                "plt.xlabel('Crop Health Status')\n",
                "plt.ylabel('Number of Samples')\n",
                "plt.xticks(rotation=0)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ü§ñ TASK 2: MACHINE LEARNING MODEL COMPARISON\n",
                "\n",
                "### üîπ Step 1: Separating Features and Target\n",
                "\n",
                "#### 2.1 What are we doing?\n",
                "Splitting data into:\n",
                "- **X (Features)**: The information we use to make predictions (vegetation indices)\n",
                "- **y (Target)**: What we want to predict (Healthy/Stressed)\n",
                "\n",
                "#### 2.2 Why separate them?\n",
                "ML models need to know: \"Here's the input (X), learn to predict the output (y)\"\n",
                "\n",
                "#### 2.3 Real-Life Analogy\n",
                "- **X** = Student's study habits, attendance, homework scores\n",
                "- **y** = Final exam result (Pass/Fail)\n",
                "\n",
                "The model learns: \"Given these habits, what's the likely result?\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# SEPARATING FEATURES AND TARGET\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\nü§ñ TASK 2: MACHINE LEARNING MODEL COMPARISON\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Define feature columns (vegetation indices only, not grid coordinates)\n",
                "feature_columns = ['ndvi_mean', 'ndvi_std', 'ndvi_min', 'ndvi_max', 'gndvi', \n",
                "                   'savi', 'evi', 'red_edge_1', 'red_edge_2', 'nir_reflectance',\n",
                "                   'soil_brightness', 'canopy_density', 'moisture_index']\n",
                "\n",
                "# X = Features (input data)\n",
                "X = df[feature_columns]\n",
                "\n",
                "# y = Target (what we predict)\n",
                "y = df['crop_health_label']\n",
                "\n",
                "print(f\"\\nüîß Data Preparation Summary:\")\n",
                "print(f\"   ‚Ä¢ Number of features: {len(feature_columns)}\")\n",
                "print(f\"   ‚Ä¢ Number of samples: {len(X)}\")\n",
                "print(f\"   ‚Ä¢ Target variable: crop_health_label (Healthy/Stressed)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Step 2: Encoding Labels\n",
                "\n",
                "#### 2.1 What is label encoding?\n",
                "Converting text labels to numbers that computers understand.\n",
                "\n",
                "#### 2.2 Why do we need this?\n",
                "Computers can't do math with words like \"Healthy\" or \"Stressed\" - they need numbers!\n",
                "\n",
                "#### 2.3 How LabelEncoder works:\n",
                "```\n",
                "\"Healthy\"  ‚Üí 0\n",
                "\"Stressed\" ‚Üí 1\n",
                "```\n",
                "\n",
                "#### 2.4 fit_transform() explained:\n",
                "- **fit()**: Learn the mapping (which label = which number)\n",
                "- **transform()**: Apply the mapping to the data\n",
                "- **fit_transform()**: Do both at once"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# ENCODING LABELS\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\nüè∑Ô∏è Encoding target labels...\")\n",
                "\n",
                "# Create encoder object\n",
                "label_encoder = LabelEncoder()\n",
                "\n",
                "# Fit (learn) and transform (apply) in one step\n",
                "y_encoded = label_encoder.fit_transform(y)\n",
                "\n",
                "print(f\"   Original labels: {list(label_encoder.classes_)}\")\n",
                "print(f\"   Encoded values:  {list(range(len(label_encoder.classes_)))}\")\n",
                "print(f\"   ‚úÖ Encoding: 'Healthy' ‚Üí 0, 'Stressed' ‚Üí 1\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Step 3: Train-Test Split\n",
                "\n",
                "#### 2.1 What is train-test split?\n",
                "Dividing data into:\n",
                "- **Training set (80%)**: Data the model learns from\n",
                "- **Testing set (20%)**: Data we use to evaluate the model\n",
                "\n",
                "#### 2.2 Why is this CRITICAL?\n",
                "You can't test students on questions they already practiced! That's cheating!\n",
                "Similarly, we can't test models on data they already saw.\n",
                "\n",
                "#### 2.3 Important Parameters:\n",
                "\n",
                "| Parameter | Value | Meaning |\n",
                "|-----------|-------|----------|\n",
                "| `test_size` | 0.2 | 20% for testing, 80% for training |\n",
                "| `random_state` | 42 | Seed for reproducibility (same split every run) |\n",
                "| `stratify` | y | Keep same class ratio in train/test |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# TRAIN-TEST SPLIT\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\n‚úÇÔ∏è Splitting data into train (80%) and test (20%) sets...\")\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X,              # Features\n",
                "    y_encoded,      # Target (encoded)\n",
                "    test_size=0.2,  # 20% for testing\n",
                "    random_state=42,  # For reproducibility\n",
                "    stratify=y_encoded  # Keep class ratio balanced\n",
                ")\n",
                "\n",
                "print(f\"   ‚Ä¢ Training samples: {len(X_train)} (80%)\")\n",
                "print(f\"   ‚Ä¢ Testing samples:  {len(X_test)} (20%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Step 4: Feature Scaling\n",
                "\n",
                "#### 2.1 What is feature scaling?\n",
                "Making all features have the same scale (mean=0, std=1).\n",
                "\n",
                "#### 2.2 Why is this important?\n",
                "Imagine comparing:\n",
                "- NDVI: ranges from 0 to 1\n",
                "- NIR reflectance: ranges from 0.2 to 0.9\n",
                "\n",
                "Without scaling, features with larger ranges dominate!\n",
                "\n",
                "#### 2.3 StandardScaler formula:\n",
                "```\n",
                "z = (x - mean) / std\n",
                "```\n",
                "\n",
                "#### 2.4 CRITICAL RULE:\n",
                "- `fit_transform()` on TRAINING data only\n",
                "- `transform()` on TEST data (no fitting!)\n",
                "\n",
                "Why? We can't use test data statistics - that would be cheating!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# FEATURE SCALING\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\nüìè Scaling features (StandardScaler)...\")\n",
                "\n",
                "# Create scaler object\n",
                "scaler = StandardScaler()\n",
                "\n",
                "# Fit on training data AND transform\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "\n",
                "# Only transform testing data (using training statistics)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(\"   ‚úÖ Features scaled to mean=0, std=1\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Step 5: Training and Comparing Models\n",
                "\n",
                "#### 2.1 What are we doing?\n",
                "Training 5 different ML models and comparing their performance.\n",
                "\n",
                "#### 2.2 Why compare multiple models?\n",
                "Different models work better for different problems. We need to find the BEST one!\n",
                "\n",
                "#### 2.3 Evaluation Metrics Explained:\n",
                "\n",
                "| Metric | Formula | When it matters |\n",
                "|--------|---------|----------------|\n",
                "| **Accuracy** | Correct / Total | General performance |\n",
                "| **Precision** | TP / (TP + FP) | Cost of false alarms is high |\n",
                "| **Recall** | TP / (TP + FN) | Missing cases is costly |\n",
                "| **F1-Score** | 2 √ó (P √ó R) / (P + R) | Balance needed |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# TRAINING AND COMPARING 5 MODELS\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\nüè≠ Training and Evaluating 5 Classification Models:\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Define our 5 models\n",
                "models = {\n",
                "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
                "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
                "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
                "    'SVM': SVC(probability=True, random_state=42),\n",
                "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
                "}\n",
                "\n",
                "# Store results\n",
                "results = []\n",
                "best_f1 = 0\n",
                "best_model = None\n",
                "best_model_name = None\n",
                "\n",
                "for name, model in models.items():\n",
                "    print(f\"\\nüîÑ Training: {name}...\")\n",
                "    \n",
                "    # Train the model\n",
                "    model.fit(X_train_scaled, y_train)\n",
                "    \n",
                "    # Make predictions\n",
                "    y_pred = model.predict(X_test_scaled)\n",
                "    y_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
                "    \n",
                "    # Calculate metrics\n",
                "    accuracy = accuracy_score(y_test, y_pred)\n",
                "    precision = precision_score(y_test, y_pred)\n",
                "    recall = recall_score(y_test, y_pred)\n",
                "    f1 = f1_score(y_test, y_pred)\n",
                "    roc_auc = roc_auc_score(y_test, y_proba)\n",
                "    \n",
                "    # Store results\n",
                "    results.append({\n",
                "        'Model': name,\n",
                "        'Accuracy': accuracy,\n",
                "        'Precision': precision,\n",
                "        'Recall': recall,\n",
                "        'F1-Score': f1,\n",
                "        'ROC-AUC': roc_auc\n",
                "    })\n",
                "    \n",
                "    # Track best model\n",
                "    if f1 > best_f1:\n",
                "        best_f1 = f1\n",
                "        best_model = model\n",
                "        best_model_name = name\n",
                "    \n",
                "    # Print results\n",
                "    print(f\"   Accuracy:  {accuracy:.4f}\")\n",
                "    print(f\"   Precision: {precision:.4f}\")\n",
                "    print(f\"   Recall:    {recall:.4f}\")\n",
                "    print(f\"   F1-Score:  {f1:.4f}\")\n",
                "    print(f\"   ROC-AUC:   {roc_auc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Model Comparison Table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# MODEL COMPARISON TABLE\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"üìã MODEL COMPARISON TABLE (Sorted by F1-Score)\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "results_df = pd.DataFrame(results)\n",
                "results_df = results_df.sort_values('F1-Score', ascending=False)\n",
                "print(results_df.to_string(index=False))\n",
                "\n",
                "print(f\"\\nüèÜ BEST MODEL: {best_model_name} (F1-Score: {best_f1:.4f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Visualizing Model Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# MODEL COMPARISON VISUALIZATION\n",
                "# =============================================================================\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(12, 6))\n",
                "\n",
                "x = np.arange(len(results_df))\n",
                "width = 0.15\n",
                "\n",
                "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
                "colors = ['#3498db', '#2ecc71', '#f1c40f', '#e74c3c', '#9b59b6']\n",
                "\n",
                "for i, metric in enumerate(metrics):\n",
                "    ax.bar(x + i*width, results_df[metric], width, label=metric, color=colors[i])\n",
                "\n",
                "ax.set_xlabel('Models', fontsize=12)\n",
                "ax.set_ylabel('Score', fontsize=12)\n",
                "ax.set_title('üèÜ Model Performance Comparison', fontsize=14)\n",
                "ax.set_xticks(x + width * 2)\n",
                "ax.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
                "ax.legend(loc='lower right')\n",
                "ax.set_ylim(0, 1.1)\n",
                "ax.grid(axis='y', alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Confusion Matrix for Best Model\n",
                "\n",
                "#### What is a Confusion Matrix?\n",
                "A table showing:\n",
                "- **True Positives (TP)**: Actually stressed, predicted stressed ‚úÖ\n",
                "- **True Negatives (TN)**: Actually healthy, predicted healthy ‚úÖ\n",
                "- **False Positives (FP)**: Actually healthy, predicted stressed ‚ùå\n",
                "- **False Negatives (FN)**: Actually stressed, predicted healthy ‚ùå"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# CONFUSION MATRIX\n",
                "# =============================================================================\n",
                "\n",
                "y_pred_best = best_model.predict(X_test_scaled)\n",
                "cm = confusion_matrix(y_test, y_pred_best)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
                "            xticklabels=['Healthy', 'Stressed'],\n",
                "            yticklabels=['Healthy', 'Stressed'])\n",
                "plt.title(f'üîç Confusion Matrix: {best_model_name}', fontsize=14)\n",
                "plt.ylabel('Actual Label')\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nüìä Classification Report for {best_model_name}:\\n\")\n",
                "print(classification_report(y_test, y_pred_best, target_names=['Healthy', 'Stressed']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üó∫Ô∏è TASK 3: SPATIAL ANALYSIS & VISUALIZATION\n",
                "\n",
                "### üîπ Creating a Field Stress Heatmap\n",
                "\n",
                "#### 2.1 What is a heatmap?\n",
                "A colorful map where colors represent values:\n",
                "- üü¢ **Green** = Healthy crops\n",
                "- üî¥ **Red** = Stressed crops\n",
                "\n",
                "#### 2.2 Why is this useful?\n",
                "Farmers can quickly see WHICH AREAS of their field need attention.\n",
                "\n",
                "#### 2.3 How do we create it?\n",
                "1. Predict stress for ALL grid cells\n",
                "2. Arrange by grid_x and grid_y\n",
                "3. Color based on stress probability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# SPATIAL ANALYSIS - FIELD STRESS HEATMAP\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\nüó∫Ô∏è TASK 3: SPATIAL ANALYSIS & VISUALIZATION\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "print(\"\\nüîÆ Generating predictions for all grid cells...\")\n",
                "\n",
                "# Scale ALL features (not just train/test)\n",
                "X_all_scaled = scaler.transform(X)\n",
                "\n",
                "# Predict on all data\n",
                "y_all_pred = best_model.predict(X_all_scaled)\n",
                "y_all_proba = best_model.predict_proba(X_all_scaled)[:, 1]\n",
                "\n",
                "# Add predictions to dataframe\n",
                "df['predicted_label'] = label_encoder.inverse_transform(y_all_pred)\n",
                "df['stress_probability'] = y_all_proba\n",
                "\n",
                "print(f\"   ‚úÖ Predictions generated for {len(df)} grid cells\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Stress Heatmap Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# STRESS HEATMAP\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\nüó∫Ô∏è Creating field stress heatmap...\")\n",
                "\n",
                "# Create pivot table for heatmap\n",
                "heatmap_data = df.pivot_table(\n",
                "    values='stress_probability',\n",
                "    index='grid_y',\n",
                "    columns='grid_x',\n",
                "    aggfunc='mean'\n",
                ")\n",
                "\n",
                "# Create the heatmap\n",
                "plt.figure(figsize=(14, 10))\n",
                "sns.heatmap(\n",
                "    heatmap_data,\n",
                "    cmap='RdYlGn_r',  # Red-Yellow-Green reversed (Red = stressed)\n",
                "    annot=False,\n",
                "    vmin=0,\n",
                "    vmax=1,\n",
                "    cbar_kws={'label': 'Stress Probability'}\n",
                ")\n",
                "plt.title('üåæ Field Stress Heatmap\\n(Red = Stressed, Green = Healthy)', fontsize=14)\n",
                "plt.xlabel('Grid X (Column)')\n",
                "plt.ylabel('Grid Y (Row)')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Summary statistics\n",
                "print(\"\\nüìä Stress Distribution Summary:\")\n",
                "stress_counts = df['predicted_label'].value_counts()\n",
                "for label, count in stress_counts.items():\n",
                "    percentage = count / len(df) * 100\n",
                "    emoji = \"üü¢\" if label == \"Healthy\" else \"üî¥\"\n",
                "    print(f\"   {emoji} {label}: {count} cells ({percentage:.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üöÅ TASK 4: DRONE INSPECTION RECOMMENDATIONS\n",
                "\n",
                "### üîπ Prioritizing Inspection Zones\n",
                "\n",
                "Based on stress probability, we categorize zones:\n",
                "\n",
                "| Priority | Stress Level | Action |\n",
                "|----------|-------------|--------|\n",
                "| üî¥ CRITICAL | ‚â•80% | Inspect IMMEDIATELY |\n",
                "| üü† HIGH | 60-80% | Inspect within 24 hours |\n",
                "| üü° MODERATE | 40-60% | Schedule inspection |\n",
                "| üü¢ LOW | 20-40% | Monitor regularly |\n",
                "| ‚úÖ HEALTHY | <20% | No action needed |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# DRONE INSPECTION RECOMMENDATIONS\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\nüöÅ TASK 4: DRONE INSPECTION RECOMMENDATIONS\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Categorize stress levels\n",
                "def categorize_stress(prob):\n",
                "    if prob >= 0.8:\n",
                "        return 'CRITICAL'\n",
                "    elif prob >= 0.6:\n",
                "        return 'HIGH'\n",
                "    elif prob >= 0.4:\n",
                "        return 'MODERATE'\n",
                "    elif prob >= 0.2:\n",
                "        return 'LOW'\n",
                "    else:\n",
                "        return 'HEALTHY'\n",
                "\n",
                "df['stress_priority'] = df['stress_probability'].apply(categorize_stress)\n",
                "\n",
                "print(\"\\nüìã INSPECTION PRIORITY ZONES:\")\n",
                "priority_counts = df['stress_priority'].value_counts()\n",
                "priority_order = ['CRITICAL', 'HIGH', 'MODERATE', 'LOW', 'HEALTHY']\n",
                "priority_emoji = {'CRITICAL': 'üî¥', 'HIGH': 'üü†', 'MODERATE': 'üü°', 'LOW': 'üü¢', 'HEALTHY': '‚úÖ'}\n",
                "\n",
                "for priority in priority_order:\n",
                "    if priority in priority_counts.index:\n",
                "        count = priority_counts[priority]\n",
                "        percentage = count / len(df) * 100\n",
                "        emoji = priority_emoji[priority]\n",
                "        print(f\"   {emoji} {priority}: {count} cells ({percentage:.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "### üîπ Specific Zone Recommendations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# SPECIFIC ZONE RECOMMENDATIONS\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\nüöÅ RECOMMENDED DRONE FLIGHT PATH:\")\n",
                "\n",
                "critical_zones = df[df['stress_priority'] == 'CRITICAL'][['grid_x', 'grid_y', 'stress_probability']]\n",
                "high_zones = df[df['stress_priority'] == 'HIGH'][['grid_x', 'grid_y', 'stress_probability']]\n",
                "\n",
                "if len(critical_zones) > 0:\n",
                "    print(\"\\n‚ö†Ô∏è CRITICAL ZONES - Inspect IMMEDIATELY:\")\n",
                "    for _, row in critical_zones.head(5).iterrows():\n",
                "        print(f\"   üìç Grid ({int(row['grid_x'])}, {int(row['grid_y'])}) - Stress: {row['stress_probability']:.1%}\")\n",
                "    if len(critical_zones) > 5:\n",
                "        print(f\"   ... and {len(critical_zones)-5} more critical zones\")\n",
                "\n",
                "if len(high_zones) > 0:\n",
                "    print(\"\\nüü† HIGH PRIORITY - Inspect within 24 hours:\")\n",
                "    for _, row in high_zones.head(5).iterrows():\n",
                "        print(f\"   üìç Grid ({int(row['grid_x'])}, {int(row['grid_y'])}) - Stress: {row['stress_probability']:.1%}\")\n",
                "\n",
                "print(\"\\nüí° INTERPRETATION GUIDELINES:\")\n",
                "print(\"   1. Critical zones require immediate ground inspection\")\n",
                "print(\"   2. High stress may indicate pest infestation or water stress\")\n",
                "print(\"   3. Consider sending follow-up drones with higher resolution\")\n",
                "print(\"   4. Compare with historical data for trend analysis\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìù TASK 5: REFLECTION\n",
                "\n",
                "### üîπ Current Limitations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# REFLECTION ON LIMITATIONS AND IMPROVEMENTS\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\nüìù TASK 5: REFLECTION\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "print(\"\"\"\n",
                "‚ö†Ô∏è CURRENT LIMITATIONS:\n",
                "\n",
                "1. üìä Dataset Size:\n",
                "   - Current dataset is limited in size\n",
                "   - Real-world farms have millions of data points\n",
                "   - More data would improve model accuracy\n",
                "\n",
                "2. üå¶Ô∏è Temporal Data Missing:\n",
                "   - We have single snapshot, not time series\n",
                "   - Plant stress develops over time\n",
                "   - Tracking trends would improve prediction\n",
                "\n",
                "3. üå°Ô∏è Weather Data Not Included:\n",
                "   - Temperature, rainfall affect plant health\n",
                "   - Integrating weather would improve accuracy\n",
                "\n",
                "4. ü¶† No Disease/Pest Classification:\n",
                "   - Current model only detects \"stress\"\n",
                "   - Doesn't tell us WHAT is causing stress\n",
                "   - Multi-class classification would be better\n",
                "\n",
                "üöÄ PROPOSED IMPROVEMENTS:\n",
                "\n",
                "1. üîÑ Time Series Analysis using LSTM networks\n",
                "2. üß† Deep Learning on raw drone imagery\n",
                "3. üåê Multi-source data fusion (weather + soil sensors)\n",
                "4. üì± Real-time edge computing on drones\n",
                "5. ü§ù Farmer feedback loop for model improvement\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ‚úÖ PROJECT SUMMARY"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# PROJECT SUMMARY\n",
                "# =============================================================================\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"‚úÖ PROJECT EXECUTION COMPLETE\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "print(f\"\"\"\n",
                "üèÜ KEY FINDINGS:\n",
                "   ‚Ä¢ Best Model: {best_model_name}\n",
                "   ‚Ä¢ F1-Score: {best_f1:.4f}\n",
                "   ‚Ä¢ Total Grid Cells Analyzed: {len(df)}\n",
                "   ‚Ä¢ Stressed Cells Identified: {len(df[df['predicted_label'] == 'Stressed'])}\n",
                "   ‚Ä¢ Critical Zones: {len(df[df['stress_priority'] == 'CRITICAL'])}\n",
                "\n",
                "üéØ RECOMMENDATIONS:\n",
                "   1. Deploy drone to critical zones first\n",
                "   2. Take close-up images of stressed plants\n",
                "   3. Consult agronomist for treatment plan\n",
                "   4. Schedule re-scan after treatment\n",
                "\n",
                "üåæ Thank you for using AI Crop Health Monitoring! üöÅ\n",
                "\"\"\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}