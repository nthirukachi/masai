# AS28: Introduction to Classification with Logistic Regression ‚Äî Exam Preparation

---

## Section A: Multiple Choice Questions (MCQ) ‚Äî 15 Questions

---

### MCQ 1
**Question:** What type of machine learning task is classification?
- A) Unsupervised learning
- B) Reinforcement learning
- C) Supervised learning
- D) Semi-supervised learning

<details>
<summary>‚úÖ Answer</summary>

**C) Supervised learning**

**Explanation:** Classification is supervised learning because it learns from labeled training data ‚Äî each data point has both features (input) and a target label (output). The model learns the mapping from features to labels during training.

**Why others are wrong:**
- A) Unsupervised learning has no labels (e.g., clustering)
- B) Reinforcement learning learns through rewards/penalties
- D) Semi-supervised uses mix of labeled and unlabeled
</details>

---

### MCQ 2
**Question:** What is the range of the sigmoid function output?
- A) -1 to 1
- B) 0 to 1
- C) -‚àû to +‚àû
- D) 0 to ‚àû

<details>
<summary>‚úÖ Answer</summary>

**B) 0 to 1**

**Explanation:** The sigmoid function œÉ(z) = 1/(1+e^(-z)) always produces output strictly between 0 and 1. When z ‚Üí +‚àû, œÉ(z) ‚Üí 1. When z ‚Üí -‚àû, œÉ(z) ‚Üí 0. It never actually reaches 0 or 1, but gets arbitrarily close.

**Why others are wrong:**
- A) This is the range of tanh (hyperbolic tangent), not sigmoid
- C) This is the range of LINEAR regression output, not sigmoid
- D) This is the range of ReLU activation
</details>

---

### MCQ 3
**Question:** What does sigmoid(0) equal?
- A) 0
- B) 1
- C) 0.5
- D) Undefined

<details>
<summary>‚úÖ Answer</summary>

**C) 0.5**

**Explanation:** sigmoid(0) = 1/(1+e^0) = 1/(1+1) = 1/2 = 0.5. This is the point of maximum uncertainty ‚Äî the model is exactly 50-50. This always holds regardless of the model, features, or data.
</details>

---

### MCQ 4
**Question:** Why does linear regression fail for classification tasks?
- A) Linear regression is too complex for classification
- B) Linear regression produces unbounded outputs that can't be interpreted as probabilities
- C) Linear regression requires more data than classification algorithms
- D) Linear regression doesn't use gradient descent

<details>
<summary>‚úÖ Answer</summary>

**B) Linear regression produces unbounded outputs that can't be interpreted as probabilities**

**Explanation:** Linear regression outputs values from -‚àû to +‚àû. Classification needs probabilities (0-1). A prediction of 1.8 means "180% likely" which is meaningless. Also, linear regression uses MSE loss which optimizes numerical distance, not classification accuracy.

**Why others are wrong:**
- A) Linear regression is simpler, not more complex
- C) Data requirement depends on features, not algorithm type
- D) Linear regression CAN use gradient descent, and also has OLS
</details>

---

### MCQ 5
**Question:** What loss function does logistic regression use?
- A) Mean Squared Error (MSE)
- B) Mean Absolute Error (MAE)
- C) Log Loss (Cross-Entropy)
- D) Hinge Loss

<details>
<summary>‚úÖ Answer</summary>

**C) Log Loss (Cross-Entropy)**

**Explanation:** Log Loss = -(1/n) √ó Œ£[y√ólog(p) + (1-y)√ólog(1-p)]. It penalizes confident wrong predictions heavily. If model confidently predicts class 1 (p=0.99) but actual is 0, the loss is enormous. MSE doesn't penalize classification errors proportionally.

**Why others are wrong:**
- A) MSE is for linear regression ‚Äî doesn't penalize wrong classifications properly
- B) MAE is for regression tasks
- D) Hinge loss is for SVM
</details>

---

### MCQ 6
**Question:** In logistic regression, the decision boundary when z = w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + b = 0 is:
- A) Always a curve
- B) Always a straight line (in 2D)
- C) Sometimes straight, sometimes curved
- D) A circle

<details>
<summary>‚úÖ Answer</summary>

**B) Always a straight line (in 2D)**

**Explanation:** The equation w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + b = 0 is a linear equation in 2D, which always represents a straight line. Logistic regression is a LINEAR classifier ‚Äî its decision boundary is always linear (straight line in 2D, hyperplane in higher dimensions).
</details>

---

### MCQ 7
**Question:** What is the threshold in logistic regression?
- A) A parameter learned during training
- B) The bias term in the model
- C) A probability cutoff chosen AFTER training to convert probabilities to class labels
- D) The learning rate for gradient descent

<details>
<summary>‚úÖ Answer</summary>

**C) A probability cutoff chosen AFTER training to convert probabilities to class labels**

**Explanation:** The threshold is NOT part of model training. During training, the model learns weights and bias to predict probabilities. After training, WE choose a threshold (default 0.5) based on business needs to convert probabilities into final class decisions.

**Common trap:** Many beginners think threshold is learned during training ‚Äî it's NOT!
</details>

---

### MCQ 8
**Question:** In a confusion matrix, a False Positive (FP) means:
- A) Model predicted Positive AND actual was Positive
- B) Model predicted Negative AND actual was Positive
- C) Model predicted Positive BUT actual was Negative
- D) Model predicted Negative AND actual was Negative

<details>
<summary>‚úÖ Answer</summary>

**C) Model predicted Positive BUT actual was Negative**

**Explanation:** False Positive = the "positive prediction" was "false" (wrong). The model raised a false alarm. Example: Model said "spam" but email was actually NOT spam.

**Memory trick:** Read as "Falsely said Positive" ‚Üí Predicted positive incorrectly.
</details>

---

### MCQ 9
**Question:** Precision is calculated as:
- A) TP / (TP + FN)
- B) TP / (TP + FP)
- C) TN / (TN + FP)
- D) (TP + TN) / (TP + TN + FP + FN)

<details>
<summary>‚úÖ Answer</summary>

**B) TP / (TP + FP)**

**Explanation:** Precision answers "Of all POSITIVE predictions, how many were actually correct?" Denominator = all positive predictions (TP + FP), numerator = correct positive predictions (TP).

**Why others are wrong:**
- A) This is Recall (TP / All Actual Positives)
- C) This is Specificity or TNR
- D) This is Accuracy
</details>

---

### MCQ 10
**Question:** In medical diagnosis, which metric should be prioritized?
- A) Accuracy
- B) Precision
- C) Recall
- D) Specificity

<details>
<summary>‚úÖ Answer</summary>

**C) Recall**

**Explanation:** In medical diagnosis, missing a disease (False Negative) is life-threatening. Recall = TP/(TP+FN) measures "how many actual disease cases did we catch?" Using a lower threshold maximizes recall ‚Äî better to test 100 healthy people than miss 1 sick person.

**Why others are wrong:**
- A) Accuracy is misleading, especially if disease is rare
- B) Precision matters when FP is costly, but in medicine, FN (missed disease) is much worse than FP (unnecessary test)
- D) Specificity measures TN rate, not as critical here
</details>

---

### MCQ 11
**Question:** F1-Score uses _____ mean of precision and recall.
- A) Arithmetic
- B) Geometric
- C) Harmonic
- D) Weighted

<details>
<summary>‚úÖ Answer</summary>

**C) Harmonic**

**Explanation:** F1 = 2√ó(P√óR)/(P+R) = harmonic mean. Harmonic mean penalizes extreme values more than arithmetic mean. If precision=0.99 and recall=0.01: arithmetic mean=0.50 (looks OK), harmonic mean=0.02 (correctly terrible).
</details>

---

### MCQ 12
**Question:** Which of the following is TRUE about logistic regression?
- A) It can only handle linearly separable data
- B) Despite its name, it is a classification algorithm
- C) It uses MSE as loss function
- D) It produces unbounded outputs

<details>
<summary>‚úÖ Answer</summary>

**B) Despite its name, it is a classification algorithm**

**Explanation:** The name "logistic regression" is historical ‚Äî it internally regresses on probabilities (continuous 0-1), but the final output is a class label. It predicts the probability of belonging to class 1, then applies a threshold for classification.

**Why others are wrong:**
- A) It can work with non-separable data too (it just won't achieve perfect accuracy)
- C) It uses Log Loss (Cross-Entropy), not MSE
- D) Sigmoid ensures output is bounded between 0 and 1
</details>

---

### MCQ 13
**Question:** If a model has 95% accuracy on data with 950 negatives and 50 positives, what could this indicate?
- A) Excellent model performance
- B) The model may be predicting "negative" for everything
- C) The model has perfect precision
- D) The model has high recall

<details>
<summary>‚úÖ Answer</summary>

**B) The model may be predicting "negative" for everything**

**Explanation:** With 950/1000 negatives, a trivial model that always predicts "negative" gets 950/1000 = 95% accuracy. But it catches zero positives (recall = 0). This is why accuracy is misleading with imbalanced data. Always check precision and recall alongside accuracy.
</details>

---

### MCQ 14
**Question:** What happens when you LOWER the classification threshold from 0.5 to 0.3?
- A) Both precision and recall increase
- B) Precision increases, recall decreases
- C) Precision decreases, recall increases
- D) Both precision and recall decrease

<details>
<summary>‚úÖ Answer</summary>

**C) Precision decreases, recall increases**

**Explanation:** Lower threshold ‚Üí more samples predicted as positive ‚Üí catches more actual positives (recall ‚Üë) but also more false alarms (precision ‚Üì). This is the precision-recall tradeoff.
</details>

---

### MCQ 15
**Question:** The derivative of sigmoid function œÉ(z) is:
- A) œÉ(z) + (1 - œÉ(z))
- B) œÉ(z) √ó (1 - œÉ(z))
- C) 1 / œÉ(z)
- D) œÉ(z)¬≤

<details>
<summary>‚úÖ Answer</summary>

**B) œÉ(z) √ó (1 - œÉ(z))**

**Explanation:** The sigmoid derivative œÉ'(z) = œÉ(z) √ó (1 - œÉ(z)). This means the gradient is maximum at z=0 (where œÉ=0.5, derivative=0.25) and approaches 0 at extreme z values (vanishing gradient problem). This elegant property makes calculus computations efficient.
</details>

---

## Section B: Multiple Select Questions (MSQ) ‚Äî 12 Questions

---

### MSQ 1
**Question:** Which of the following are reasons why linear regression fails for classification? (Select ALL that apply)
- A) ‚òê Outputs can be less than 0
- B) ‚òê Outputs can be greater than 1
- C) ‚òê Uses MSE loss instead of log loss
- D) ‚òê Cannot handle categorical features
- E) ‚òê Sensitive to outliers which shift the decision boundary

<details>
<summary>‚úÖ Answer</summary>

**A, B, C, E**

- ‚úÖA: Linear regression can predict negative values, meaningless as probability
- ‚úÖB: Linear regression can predict >1 values, meaningless as probability
- ‚úÖC: MSE optimizes numerical distance, not classification accuracy
- ‚ùåD: Categorical features can be encoded for linear regression ‚Äî this is not classification-specific
- ‚úÖE: Outliers tilt the regression line, shifting the decision boundary unfairly
</details>

---

### MSQ 2
**Question:** Which of the following are properties of the sigmoid function? (Select ALL that apply)
- A) ‚òê Output is always between 0 and 1
- B) ‚òê S-shaped curve
- C) ‚òê sigmoid(0) = 0
- D) ‚òê Differentiable everywhere
- E) ‚òê Output can be interpreted as probability

<details>
<summary>‚úÖ Answer</summary>

**A, B, D, E**

- ‚úÖA: Output always in (0, 1) ‚Äî mathematical proof: e^(-z) > 0 always
- ‚úÖB: Classic S-shaped curve with smooth transition
- ‚ùåC: sigmoid(0) = 0.5, NOT 0!
- ‚úÖD: Derivative œÉ'(z) = œÉ(z)(1-œÉ(z)) exists everywhere
- ‚úÖE: Output represents P(class=1|x), valid probability interpretation
</details>

---

### MSQ 3
**Question:** In which scenarios should you use a LOW threshold (e.g., 0.3)? (Select ALL that apply)
- A) ‚òê Medical disease screening
- B) ‚òê Spam email filtering
- C) ‚òê Fraud detection
- D) ‚òê Security threat detection
- E) ‚òê Product recommendation

<details>
<summary>‚úÖ Answer</summary>

**A, C, D**

- ‚úÖA: Missing disease (FN) is life-threatening ‚Äî catch every possible case
- ‚ùåB: Spam filtering needs HIGH threshold ‚Äî losing important email (FP) is worse
- ‚úÖC: Missing fraud (FN) = financial loss ‚Äî flag everything suspicious
- ‚úÖD: Missing threat (FN) = security breach ‚Äî catch all potential threats
- ‚ùåE: Product recommendation can use balanced threshold ‚Äî FP just means irrelevant suggestion
</details>

---

### MSQ 4
**Question:** Which of the following correctly describe the confusion matrix terms? (Select ALL that apply)
- A) ‚òê True Positive = Model predicted positive, actual was positive
- B) ‚òê False Negative = Model predicted negative, actual was positive
- C) ‚òê False Positive = Model predicted positive, actual was positive
- D) ‚òê True Negative = Model predicted negative, actual was negative

<details>
<summary>‚úÖ Answer</summary>

**A, B, D**

- ‚úÖA: TP ‚Äî correct positive prediction ‚úÖ
- ‚úÖB: FN ‚Äî model missed a positive (dangerous!) ‚ùå
- ‚ùåC: This describes TRUE Positive, not FALSE Positive. FP = predicted positive, actual was NEGATIVE
- ‚úÖD: TN ‚Äî correct negative prediction ‚úÖ
</details>

---

### MSQ 5
**Question:** Which of these are advantages of logistic regression? (Select ALL that apply)
- A) ‚òê Highly interpretable ‚Äî coefficients show feature impact
- B) ‚òê Can capture non-linear decision boundaries
- C) ‚òê Produces natural probability output
- D) ‚òê Fast to train
- E) ‚òê Works well with small datasets
- F) ‚òê Foundation for neural networks

<details>
<summary>‚úÖ Answer</summary>

**A, C, D, E, F**

- ‚úÖA: Coefficients directly show how much each feature affects prediction
- ‚ùåB: Standard logistic regression only produces LINEAR boundaries ‚Äî non-linear needs polynomial features or other algorithms
- ‚úÖC: Sigmoid naturally outputs valid probabilities (0-1)
- ‚úÖD: Convex optimization, converges quickly
- ‚úÖE: Doesn't need large datasets unlike neural networks
- ‚úÖF: Sigmoid appears in neural networks repeatedly
</details>

---

### MSQ 6
**Question:** When accuracy is misleading, which metrics should you check? (Select ALL that apply)
- A) ‚òê Precision
- B) ‚òê Recall
- C) ‚òê F1-Score
- D) ‚òê R¬≤ Score
- E) ‚òê Confusion Matrix

<details>
<summary>‚úÖ Answer</summary>

**A, B, C, E**

- ‚úÖA: Precision reveals if positive predictions are correct
- ‚úÖB: Recall reveals if actual positives are caught
- ‚úÖC: F1 balances precision and recall in single metric
- ‚ùåD: R¬≤ is for REGRESSION, not classification
- ‚úÖE: Confusion matrix gives complete breakdown of TP, TN, FP, FN
</details>

---

### MSQ 7
**Question:** Which are components of the logistic regression pipeline? (Select ALL that apply)
- A) ‚òê Linear combination z = wx + b
- B) ‚òê Sigmoid activation
- C) ‚òê Threshold-based decision
- D) ‚òê Polynomial feature generation
- E) ‚òê Log loss optimization

<details>
<summary>‚úÖ Answer</summary>

**A, B, C, E**

- ‚úÖA: First step ‚Äî compute raw linear score z
- ‚úÖB: Second step ‚Äî convert z to probability via sigmoid
- ‚úÖC: Third step ‚Äî apply threshold for final class prediction
- ‚ùåD: Polynomial features are optional enhancement, not core pipeline component
- ‚úÖE: Training process ‚Äî optimize weights by minimizing log loss
</details>

---

### MSQ 8
**Question:** Which statements about F1-Score are correct? (Select ALL that apply)
- A) ‚òê F1 = harmonic mean of precision and recall
- B) ‚òê F1 is high only when BOTH precision and recall are high
- C) ‚òê F1 = (precision + recall) / 2
- D) ‚òê F1 penalizes extreme imbalance between precision and recall
- E) ‚òê F1 ranges from 0 to 1

<details>
<summary>‚úÖ Answer</summary>

**A, B, D, E**

- ‚úÖA: F1 = 2√ó(P√óR)/(P+R) ‚Äî harmonic mean formula
- ‚úÖB: Harmonic mean requires both values to be high
- ‚ùåC: This is ARITHMETIC mean, not harmonic mean
- ‚úÖD: If one is very low, F1 drops significantly
- ‚úÖE: F1 minimum is 0 (worst), maximum is 1 (perfect)
</details>

---

### MSQ 9
**Question:** Which of the following are valid alternatives to sigmoid for classification? (Select ALL that apply)
- A) ‚òê Softmax (for multi-class)
- B) ‚òê ReLU (for hidden layers)
- C) ‚òê Decision Trees (different algorithm)
- D) ‚òê Linear function (unbounded)
- E) ‚òê SVM (with probability calibration)

<details>
<summary>‚úÖ Answer</summary>

**A, C, E**

- ‚úÖA: Softmax generalizes sigmoid for multi-class ‚Äî outputs sum to 1
- ‚ùåB: ReLU is for hidden layers in neural networks, not for classification output (unbounded)
- ‚úÖC: Decision trees are alternative classification algorithm (non-linear boundaries)
- ‚ùåD: Linear function is unbounded ‚Äî the very problem sigmoid solves
- ‚úÖE: SVM can do classification, and with calibration, can output probabilities
</details>

---

### MSQ 10
**Question:** What happens when the classification threshold is increased from 0.5 to 0.8? (Select ALL that apply)
- A) ‚òê Fewer samples predicted as positive
- B) ‚òê False positives decrease
- C) ‚òê False negatives increase
- D) ‚òê Recall increases
- E) ‚òê Precision typically increases

<details>
<summary>‚úÖ Answer</summary>

**A, B, C, E**

- ‚úÖA: Higher bar for "positive" ‚Üí fewer pass the threshold
- ‚úÖB: Only very confident predictions labeled positive ‚Üí fewer false alarms
- ‚úÖC: Some actual positives below 0.8 threshold get labeled negative ‚Üí more misses
- ‚ùåD: Recall DECREASES because we miss more actual positives (FN increases)
- ‚úÖE: Positive predictions are more confident ‚Üí higher proportion are correct
</details>

---

### MSQ 11
**Question:** Which of the following correctly describe the logistic regression training process? (Select ALL that apply)
- A) ‚òê Uses gradient descent for optimization
- B) ‚òê Has a closed-form solution like OLS
- C) ‚òê Minimizes log loss (cross-entropy)
- D) ‚òê Learns weights w and bias b
- E) ‚òê Learns the optimal threshold

<details>
<summary>‚úÖ Answer</summary>

**A, C, D**

- ‚úÖA: No closed-form solution ‚Üí iterative gradient descent
- ‚ùåB: Unlike linear regression, logistic regression does NOT have a closed-form solution
- ‚úÖC: Log loss penalizes confident wrong predictions
- ‚úÖD: Model learns optimal weights and bias during training
- ‚ùåE: Threshold is chosen AFTER training by the user, NOT learned by the model
</details>

---

### MSQ 12
**Question:** For spam detection, which design choices are appropriate? (Select ALL that apply)
- A) ‚òê Use higher threshold (0.7+) to avoid losing important emails
- B) ‚òê Prioritize precision over recall
- C) ‚òê Use logistic regression as baseline model
- D) ‚òê Use low threshold (0.3) to catch all spam
- E) ‚òê Monitor false positive rate in production

<details>
<summary>‚úÖ Answer</summary>

**A, B, C, E**

- ‚úÖA: Higher threshold ‚Üí fewer false alarms ‚Üí fewer important emails lost
- ‚úÖB: FP (losing important email) is worse than FN (spam in inbox) ‚Üí precision matters
- ‚úÖC: Logistic regression is excellent baseline for text classification
- ‚ùåD: Low threshold catches more spam but also marks important emails as spam
- ‚úÖE: Monitoring FP rate ensures important emails aren't being lost
</details>

---

## Section C: Numerical Questions ‚Äî 8 Questions

---

### Numerical 1
**Question:** Calculate sigmoid(-2). Round to 4 decimal places.

<details>
<summary>‚úÖ Answer</summary>

**0.1192**

**Calculation:**
```
sigmoid(-2) = 1 / (1 + e^(-(-2)))
            = 1 / (1 + e^2)
            = 1 / (1 + 7.389)
            = 1 / 8.389
            = 0.1192
```
</details>

---

### Numerical 2
**Question:** Given TP=40, FP=10, FN=5, TN=45, calculate Precision. Round to 4 decimal places.

<details>
<summary>‚úÖ Answer</summary>

**0.8000**

**Calculation:**
```
Precision = TP / (TP + FP)
          = 40 / (40 + 10)
          = 40 / 50
          = 0.8000
```
</details>

---

### Numerical 3
**Question:** Given TP=40, FP=10, FN=5, TN=45, calculate Recall. Round to 4 decimal places.

<details>
<summary>‚úÖ Answer</summary>

**0.8889**

**Calculation:**
```
Recall = TP / (TP + FN)
       = 40 / (40 + 5)
       = 40 / 45
       = 0.8889
```
</details>

---

### Numerical 4
**Question:** Given Precision=0.80 and Recall=0.8889, calculate F1-Score. Round to 4 decimal places.

<details>
<summary>‚úÖ Answer</summary>

**0.8421**

**Calculation:**
```
F1 = 2 √ó (Precision √ó Recall) / (Precision + Recall)
   = 2 √ó (0.80 √ó 0.8889) / (0.80 + 0.8889)
   = 2 √ó 0.7111 / 1.6889
   = 1.4222 / 1.6889
   = 0.8421
```
</details>

---

### Numerical 5
**Question:** Given TP=40, FP=10, FN=5, TN=45, calculate Accuracy. Express as percentage.

<details>
<summary>‚úÖ Answer</summary>

**85.00%**

**Calculation:**
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
         = (40 + 45) / (40 + 45 + 10 + 5)
         = 85 / 100
         = 0.85 = 85.00%
```
</details>

---

### Numerical 6
**Question:** In the spam detector example, z = -2 + 0.5 √ó num_exclamation_marks. How many exclamation marks make z = 0 (decision boundary)?

<details>
<summary>‚úÖ Answer</summary>

**4 exclamation marks**

**Calculation:**
```
z = 0 ‚Üí -2 + 0.5 √ó x = 0
       ‚Üí 0.5 √ó x = 2
       ‚Üí x = 4
```
At 4 exclamation marks, z=0, sigmoid=0.5, model is exactly uncertain.
</details>

---

### Numerical 7
**Question:** If Precision = 0.95 and Recall = 0.05, what is the F1-Score? Round to 4 decimal places.

<details>
<summary>‚úÖ Answer</summary>

**0.0950**

**Calculation:**
```
F1 = 2 √ó (0.95 √ó 0.05) / (0.95 + 0.05)
   = 2 √ó 0.0475 / 1.00
   = 0.0950
```

**Key insight:** Despite high precision (0.95), low recall (0.05) makes F1 terrible. Harmonic mean correctly penalizes this extreme imbalance. Arithmetic mean would be (0.95+0.05)/2 = 0.50 ‚Äî misleadingly decent.
</details>

---

### Numerical 8
**Question:** Given confusion matrix [[80, 5], [15, 100]], calculate:
a) Accuracy b) Precision c) Recall d) F1

<details>
<summary>‚úÖ Answer</summary>

**Mapping:** TN=80, FP=5, FN=15, TP=100

**a) Accuracy = (TP+TN)/(Total) = (100+80)/200 = 180/200 = 0.9000 = 90%**

**b) Precision = TP/(TP+FP) = 100/(100+5) = 100/105 = 0.9524**

**c) Recall = TP/(TP+FN) = 100/(100+15) = 100/115 = 0.8696**

**d) F1 = 2√ó(0.9524 √ó 0.8696)/(0.9524+0.8696) = 2√ó0.8283/1.8220 = 1.6566/1.8220 = 0.9091**
</details>

---

## Section D: Fill in the Blanks ‚Äî 10 Questions

---

### FIB 1
**Question:** Classification predicts __________ labels, while regression predicts __________ values.

<details>
<summary>‚úÖ Answer</summary>

**discrete (categorical)** ; **continuous**
</details>

---

### FIB 2
**Question:** The sigmoid function formula is œÉ(z) = 1 / (1 + __________).

<details>
<summary>‚úÖ Answer</summary>

**e^(-z)**
</details>

---

### FIB 3
**Question:** sigmoid(0) always equals __________.

<details>
<summary>‚úÖ Answer</summary>

**0.5**
</details>

---

### FIB 4
**Question:** The loss function used by logistic regression is called __________ or __________.

<details>
<summary>‚úÖ Answer</summary>

**Log Loss** ; **Cross-Entropy**
</details>

---

### FIB 5
**Question:** Precision = TP / (TP + __________) and Recall = TP / (TP + __________).

<details>
<summary>‚úÖ Answer</summary>

**FP** ; **FN**
</details>

---

### FIB 6
**Question:** F1-Score uses the __________ mean of precision and recall.

<details>
<summary>‚úÖ Answer</summary>

**harmonic**
</details>

---

### FIB 7
**Question:** The classification threshold is chosen __________ model training, not __________ model training.

<details>
<summary>‚úÖ Answer</summary>

**after** ; **during**
</details>

---

### FIB 8
**Question:** In medical diagnosis, __________ (precision/recall) is prioritized because missing a disease (__________ error) is life-threatening.

<details>
<summary>‚úÖ Answer</summary>

**recall** ; **False Negative (FN)**
</details>

---

### FIB 9
**Question:** The derivative of sigmoid function is œÉ'(z) = œÉ(z) √ó __________.

<details>
<summary>‚úÖ Answer</summary>

**(1 - œÉ(z))**
</details>

---

### FIB 10
**Question:** Logistic regression decision boundary in 2D is always a __________ because it is a __________ classifier.

<details>
<summary>‚úÖ Answer</summary>

**straight line** ; **linear**
</details>

---

## Section E: Quick Revision Points

---

### üîë Top 20 Points to Remember

1. **Classification** = predict categories (discrete labels), NOT numbers
2. **Regression** = predict continuous values (numbers)
3. **Linear regression fails** for classification ‚Üí unbounded outputs, wrong loss function
4. **Sigmoid** squashes ANY number to (0,1) ‚Üí valid probability
5. **sigmoid(0) = 0.5** ‚Üí always, mathematical truth
6. **Logistic Regression** = Linear + Sigmoid + Threshold ‚Üí 3-stage pipeline
7. **Log Loss** penalizes confident wrong predictions ‚Üí better than MSE for classification
8. **Gradient Descent** optimizes logistic regression ‚Üí no closed-form solution
9. **Decision Boundary** = where probability = 0.5 (z = 0) ‚Üí always LINEAR for logistic regression
10. **Threshold** = business decision, NOT model parameter ‚Üí chosen AFTER training
11. **Lower threshold** ‚Üí more positives, higher recall, lower precision
12. **Higher threshold** ‚Üí fewer positives, higher precision, lower recall
13. **Confusion Matrix** = TP + TN + FP + FN ‚Üí complete performance picture
14. **Accuracy** = (TP+TN)/Total ‚Üí misleading with imbalanced data!
15. **Precision** = TP/(TP+FP) ‚Üí "of my YES predictions, how many correct?"
16. **Recall** = TP/(TP+FN) ‚Üí "of actual YES, how many found?"
17. **F1-Score** = harmonic mean ‚Üí penalizes extreme imbalance
18. **Medical** ‚Üí prioritize Recall (FN = death risk)
19. **Spam** ‚Üí prioritize Precision (FP = lost important email)
20. **Logistic Regression is classification** despite "regression" in name!

---

## Section F: Shortcuts & Cheat Codes

---

### üöÄ Memory Tricks

**CLASSIFICATION vs REGRESSION:**
> "C for Categories, R for Real numbers" ‚Üí Classification predicts Categories, Regression predicts Real (continuous) numbers.

**SIGMOID properties:**
> "SOZ ‚Üí Sigmoid Of Zero = 0.5" ‚Üí Always remember sigmoid(0) = 0.5

**PRECISION vs RECALL:**
> "P = Predicted Positives quality | R = Real positives coverage"
> Precision = out of Predicted Positives | Recall = out of Real (actual) Positives

**False Positive vs False Negative:**
> "Read backwards: FP = Falsely called Positive | FN = Falsely called Negative"

**When to use LOW threshold:**
> "If MISSING is KILLING ‚Üí LOW threshold" ‚Üí Medical, Fraud, Security

**When to use HIGH threshold:**
> "If FALSE ALARM is COSTLY ‚Üí HIGH threshold" ‚Üí Spam, Recommendations

---

### üßÆ Quick Calculation Hacks

**Sigmoid shortcut values:**
| z | sigmoid | Memory trick |
|---|---------|-------------|
| -‚àû | ‚âà 0 | Very negative ‚Üí very unlikely |
| -2 | ‚âà 0.12 | ~12% ‚Äî "barely there" |
| -1 | ‚âà 0.27 | ~27% ‚Äî "quarter chance" |
| 0 | = 0.50 | "Middle ‚Äî uncertain" |
| 1 | ‚âà 0.73 | ~73% ‚Äî "three-quarter" |
| 2 | ‚âà 0.88 | ~88% ‚Äî "high confidence" |
| +‚àû | ‚âà 1 | Very positive ‚Üí very likely |

**Symmetry trick:** sigmoid(-z) = 1 - sigmoid(z)
Example: sigmoid(-2) = 1 - sigmoid(2) = 1 - 0.88 = 0.12 ‚úÖ

**F1-Score quick check:**
- If P = R ‚Üí F1 = P = R (harmonic mean of equal values = the value)
- If one is 0 ‚Üí F1 = 0
- F1 is always ‚â§ min(P, R)... wait NO ‚Üí F1 is always between min(P,R) values

**Accuracy from confusion matrix:**
> "Diagonal sum / Total" ‚Üí (TN + TP) / (TN + FP + FN + TP)

---

### üìù Last-Minute Formula Sheet

```
Sigmoid:       œÉ(z) = 1 / (1 + e^(-z))
Sigmoid':      œÉ'(z) = œÉ(z) √ó (1 - œÉ(z))
Log Loss:      -(1/n) Œ£ [y¬∑log(p) + (1-y)¬∑log(1-p)]
Accuracy:      (TP + TN) / (TP + TN + FP + FN)
Precision:     TP / (TP + FP)
Recall:        TP / (TP + FN)
Specificity:   TN / (TN + FP)
F1-Score:      2 √ó (P √ó R) / (P + R)
```

---

### üéôÔ∏è Interview One-Liners

| Question | One-Liner Answer |
|----------|-----------------|
| What is classification? | Predicting discrete categories using supervised learning |
| Why not linear regression? | Unbounded output, wrong loss function, can't produce valid probabilities |
| What does sigmoid do? | Squashes any real number into a probability between 0 and 1 |
| sigmoid(0) = ? | Always 0.5, mathematically guaranteed |
| Is logistic regression actually regression? | No ‚Äî it's classification that internally computes probabilities |
| What loss function? | Log Loss (Cross-Entropy) ‚Äî penalizes confident wrong predictions |
| What is a decision boundary? | Line/surface where model probability equals the threshold (typically 0.5) |
| Is threshold learned? | No ‚Äî chosen AFTER training based on business needs |
| Precision vs Recall? | Precision = quality of positive predictions; Recall = coverage of actual positives |
| When use F1? | When both FP and FN errors are equally costly |
| Why accuracy misleading? | Imbalanced data ‚Äî majority class predictor gets high accuracy but useless |

---

### üèÜ Golden Rules (Top 5)

1. **Always check class balance** before trusting accuracy
2. **Threshold is your business decision** ‚Äî model just gives probabilities
3. **Start with logistic regression** as baseline before trying complex models
4. **F1-Score requires BOTH** precision and recall to be good ‚Äî one alone can't save it
5. **Domain expertise determines** which metric matters most ‚Äî no universal "best metric"

---

### üîÑ Quick Decision Flowchart

```mermaid
flowchart TD
    A[Classification Problem?] --> B{Binary or Multi-class?}
    B -->|Binary| C[Start with Logistic Regression]
    B -->|Multi-class| D[Softmax Regression or<br/>One-vs-Rest LR]
    C --> E{Data linearly separable?}
    E -->|Yes| F[‚úÖ Logistic Regression works great]
    E -->|Not sure| G[Try LR first as baseline]
    E -->|No| H[Consider SVM/Trees/NN]
    
    F --> I{Choose Threshold}
    G --> I
    I --> J{What errors matter?}
    J -->|FN is costly<br/>Medical, Fraud| K[Low threshold 0.3]
    J -->|FP is costly<br/>Spam, Justice| L[High threshold 0.7]
    J -->|Balanced| M[Default 0.5]
    
    K --> N[Optimize Recall]
    L --> O[Optimize Precision]
    M --> P[Optimize F1-Score]
```

---

### üö´ Safe Answer Patterns for Exams

**"Why not linear regression for classification?"**
> "Three reasons: (1) unbounded output ‚Äî can predict values outside 0-1, (2) MSE loss doesn't optimize classification accuracy, (3) outlier sensitivity shifts decision boundary. Logistic regression solves all three via sigmoid function and log loss."

**"Explain logistic regression in 3 sentences."**
> "Logistic regression is a classification algorithm that uses a linear combination of features passed through a sigmoid function to produce probabilities. The sigmoid squashes unbounded values into 0-1 range. A threshold converts these probabilities into final class predictions."

**"Precision vs Recall ‚Äî when to prioritize which?"**
> "Prioritize Precision when False Positives are costly (spam filter, criminal conviction). Prioritize Recall when False Negatives are costly (medical diagnosis, fraud detection). Use F1-Score when both errors are equally important."

**"What is the confusion matrix?"**
> "A 2√ó2 table with four cells: TP (correctly predicted positive), TN (correctly predicted negative), FP (incorrectly predicted positive ‚Äî false alarm), FN (incorrectly predicted negative ‚Äî missed). It provides complete performance breakdown beyond just accuracy."

---

*End of Exam Preparation ‚Äî AS28: Introduction to Classification with Logistic Regression*
