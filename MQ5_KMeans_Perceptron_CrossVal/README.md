# MQ5: K-Means Feature Augmentation + Perceptron Cross-Validation

A teaching project demonstrating how to combine **unsupervised learning (K-Means clustering)** with **supervised learning (Perceptron)** and evaluate performance using **stratified 5-fold cross-validation**.

## ğŸ¯ Objective

Determine if augmenting features with K-Means cluster information (one-hot membership + centroid distances) improves Perceptron classification performance on the Wine dataset.

## ğŸ“Š Dataset

- **Source:** scikit-learn's `load_wine`
- **Samples:** 178
- **Features:** 13 (chemical measurements)
- **Original Classes:** 3 (wine cultivars)
- **Binary Task:** Class 0 (positive) vs. Classes 1 & 2 (negative)

## ğŸ”§ Key Concepts

| Concept | Description |
|---------|-------------|
| **K-Means Clustering** | Unsupervised algorithm that groups data into k clusters |
| **Perceptron** | Simplest neural network (single-layer, linear classifier) |
| **Feature Augmentation** | Adding new features derived from clustering |
| **Stratified Cross-Validation** | Preserves class distribution in each fold |
| **Data Leakage Prevention** | K-Means fit ONLY on training data per fold |

## ğŸ“ Project Structure

```
MQ5_KMeans_Perceptron_CrossVal/
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ kmeans_perceptron_crossval.ipynb    # Teaching notebook
â”œâ”€â”€ src/
â”‚   â””â”€â”€ kmeans_perceptron_crossval.py       # Python implementation
â”œâ”€â”€ documentation/
â”‚   â”œâ”€â”€ Original_Problem.md                  # Raw problem statement
â”‚   â”œâ”€â”€ problem_statement.md                 # Simplified explanation
â”‚   â”œâ”€â”€ concepts_explained.md                # 12-point concept breakdown
â”‚   â”œâ”€â”€ observations_and_conclusion.md       # Results analysis
â”‚   â”œâ”€â”€ interview_questions.md               # Q&A for interviews
â”‚   â”œâ”€â”€ exam_preparation.md                  # MCQ/MSQ/Numerical
â”‚   â””â”€â”€ interview_preparation.md             # Quick revision sheet
â”œâ”€â”€ slides/
â”‚   â””â”€â”€ slides.md                            # NotebookLM-style presentation
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ cross_validation_metrics.csv         # Metric table
â”‚   â””â”€â”€ comparison_plot.png                  # Bar chart comparison
â””â”€â”€ README.md                                # This file
```

## ğŸš€ Quick Start

```powershell
# Navigate to project directory
cd c:\masai\MQ5_KMeans_Perceptron_CrossVal

# Run Python script with UV
uv run python src/kmeans_perceptron_crossval.py

# Or run the Jupyter notebook
uv run jupyter notebook notebook/kmeans_perceptron_crossval.ipynb
```

## ğŸ“ˆ Deliverables

1. **Cross-Validation Metric Table** - Fold-wise Accuracy, F1, Average Precision
2. **Comparison Plots** - Bar charts with error bars
3. **Executive Summary** - 400-450 word recommendation for production

## ğŸ“ Learning Outcomes

After completing this project, you will understand:

- How to combine unsupervised and supervised learning
- Why K-Means must be fit per fold (data leakage prevention)
- How to create and evaluate feature augmentation pipelines
- How to use stratified cross-validation for imbalanced data
- How to perform statistical significance testing
- How to write production recommendations based on evidence

## ğŸ“ Author

Created as part of the Masai Teaching Project Series.
