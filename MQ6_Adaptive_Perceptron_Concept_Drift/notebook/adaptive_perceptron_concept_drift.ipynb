{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \ud83e\udde9 Problem Statement\n",
                "\n",
                "## 1. The Problem: Concept Drift\n",
                "Imagine you are a student preparing for a math exam. You study hard and learn all the formulas for **Algebra**. But, when you go to the exam hall, you find out the questions are now about **Geometry**! Your old formulas (Algebra) don't work well anymore. You need to **adapt**\u2014maybe unlearn some old rules and learn new ones quickly.\n",
                "\n",
                "In Machine Learning, this is called **Concept Drift**. The relationship between your inputs and outputs changes over time.\n",
                "\n",
                "## 2. Our Goal\n",
                "Build a **Perceptron** that can:\n",
                "- Learn from a stream of data.\n",
                "- Detect when its accuracy drops (Validation Check).\n",
                "- **Reset itself** or adapt when the data changes too much.\n",
                "\n",
                "## 3. Visual Flow\n",
                "```mermaid\n",
                "graph TD\n",
                "    A[Start: Data Stream] -->|Batch 1| B(Train Perceptron)\n",
                "    B --> C{Check Accuracy}\n",
                "    C -->|High Accuracy > 70%| D[Keep Learning Parameters]\n",
                "    C -->|Low Accuracy < 70%| E[\u26a0\ufe0f RESET WEIGHTS]\n",
                "    D --> F[Next Batch]\n",
                "    E --> F\n",
                "    F -->|Batch 2: Drift!| B\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udd39 Line Explanation\n",
                "#### 2.1 What the line does\n",
                "Imports necessary libraries for array manipulation (`numpy`), data handling (`pandas`), plotting (`matplotlib`), and dataset generation (`sklearn`).\n",
                "#### 2.2 Why it is used\n",
                "These are the standard tools for Data Science in Python. We need `numpy` for the perceptron math and `matplotlib` to see the results.\n",
                "#### 2.3 When to use it\n",
                "At the beginning of every data science project.\n",
                "#### 2.4 Where to use it\n",
                "Top of the file/notebook.\n",
                "#### 2.5 How to use it\n",
                "`import numpy as np`\n",
                "#### 2.6 How it works internally\n",
                "Loads the compiled C libraries for fast math operations into Python's memory.\n",
                "#### 2.7 Output with sample examples\n",
                "None (execution is silent)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.datasets import make_classification\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.model_selection import train_test_split"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udd39 Function Explanation: drifting_stream\n",
                "#### 3.1 What it does\n",
                "Generates a stream of data batches where the data distribution shifts (drifts) over time.\n",
                "#### 3.2 Why it is used\n",
                "To simulate a changing environment so we can test if our model adapts.\n",
                "#### 3.3 When to use it\n",
                "When testing online learning algorithms.\n",
                "#### 3.4 Where to use it\n",
                "In synthetic data generation steps.\n",
                "#### 3.5 How to use it\n",
                "`batches = drifting_stream()`\n",
                "#### 3.6 How it works internally\n",
                "It creates base classification data and adds specific offsets (`shifts`) to the X and Y coordinates of the features.\n",
                "#### 3.7 Output impact with examples\n",
                "Returns a list of `(X, y)` tuples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def drifting_stream(seed=99):\n",
                "    rng = np.random.default_rng(seed)\n",
                "    batches = []\n",
                "    shifts = [(0.0, 0.0), (0.8, -0.6), (1.2, 0.9)]\n",
                "    \n",
                "    for drift_x, drift_y in shifts:\n",
                "        X, y = make_classification(\n",
                "            n_samples=500,\n",
                "            n_features=2,\n",
                "            n_informative=2,\n",
                "            n_redundant=0,\n",
                "            class_sep=1.2,\n",
                "            random_state=rng.integers(1000),\n",
                "        )\n",
                "        X[:, 0] += drift_x\n",
                "        X[:, 1] += drift_y\n",
                "        batches.append((X, y))\n",
                "    return batches"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udd39 Class Explanation: AdaptivePerceptron\n",
                "#### 2.1 What this Class does\n",
                "It implements a Perceptron (linear classifier) that can decay its learning rate and reset its memory.\n",
                "#### 2.2 Why it is used\n",
                "Standard Perceptrons don't reset or decay explicitly. We need these features for our specific Concept Drift task.\n",
                "#### 2.3 When to use it\n",
                "When handling streaming data that might change drastically.\n",
                "#### 2.4 Where to use it\n",
                "As the core machine learning model.\n",
                "#### 2.5 How to use it\n",
                "`model = AdaptivePerceptron(learning_rate=0.1)`\n",
                "#### 2.6 How it works internally\n",
                "It stores `weights` and `bias`. `update_weights` adjusts them based on error. `reset_model` wipes them clean.\n",
                "#### 2.7 Output with sample examples\n",
                "An object that can `.predict(X)`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class AdaptivePerceptron:\n",
                "    def __init__(self, learning_rate=0.1, decay_rate=0.9, decay_steps=5):\n",
                "        self.initial_learning_rate = learning_rate\n",
                "        self.learning_rate = learning_rate\n",
                "        self.decay_rate = decay_rate\n",
                "        self.decay_steps = decay_steps\n",
                "        self.weights = None\n",
                "        self.bias = 0\n",
                "        self.reset_count = 0 \n",
                "        self.learning_rates_log = []\n",
                "\n",
                "    def activation(self, z):\n",
                "        # Step function: 1 if z >= 0 else 0\n",
                "        return 1 if z >= 0 else 0\n",
                "\n",
                "    def predict(self, X):\n",
                "        if self.weights is None:\n",
                "            return np.zeros(X.shape[0])\n",
                "        linear_output = np.dot(X, self.weights) + self.bias\n",
                "        y_predicted = np.array([self.activation(z) for z in linear_output])\n",
                "        return y_predicted\n",
                "\n",
                "    def update_weights(self, x_i, y_true):\n",
                "        linear_output = np.dot(x_i, self.weights) + self.bias\n",
                "        y_pred = self.activation(linear_output)\n",
                "        error = y_true - y_pred\n",
                "        if error != 0:\n",
                "            update = self.learning_rate * error\n",
                "            self.weights += update * x_i\n",
                "            self.bias += update\n",
                "\n",
                "    def reset_model(self, n_features):\n",
                "        rng = np.random.default_rng(42)\n",
                "        self.weights = rng.random(n_features) * 0.01\n",
                "        self.bias = 0\n",
                "        self.learning_rate = self.initial_learning_rate \n",
                "        self.reset_count += 1\n",
                "        print(\"  [RESET] TRIGGERED: Weights re-initialized!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udd39 Experiment Block Explanation\n",
                "#### 2.1 What this block does\n",
                "It runs the main loop: Get Batches -> Train -> Evaluate -> Reset if needed.\n",
                "#### 2.2 Why it is used\n",
                "To put everything together and see if our model works.\n",
                "#### 2.3 When to use it\n",
                "After defining data and model classes.\n",
                "#### 2.4 Where to use it\n",
                "At the end of the script/notebook.\n",
                "#### 2.5 How to use it\n",
                "Just run the cell.\n",
                "#### 2.6 How it works internally\n",
                "It loops through the generated batches, performs training loops, checks accuracy, and plotting results.\n",
                "#### 2.7 Output with sample examples\n",
                "Prints accuracy logs and displays a plot."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Get Data Stream\n",
                "batches = drifting_stream(seed=99)\n",
                "print(f\"Generated {len(batches)} batches of data.\\n\")\n",
                "\n",
                "# 2. Initialize Model\n",
                "model = AdaptivePerceptron(learning_rate=0.1, decay_rate=0.9, decay_steps=5)\n",
                "\n",
                "global_accuracies = []\n",
                "reset_points = [] \n",
                "EPOCHS_PER_BATCH = 15\n",
                "overall_epoch_counter = 0\n",
                "\n",
                "for batch_idx, (X, y) in enumerate(batches):\n",
                "    print(f\"=== BATCH {batch_idx + 1} ===\")\n",
                "    # Split data\n",
                "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=200, shuffle=True, random_state=42)\n",
                "    \n",
                "    # Initialize weights if needed\n",
                "    if model.weights is None:\n",
                "        model.reset_model(n_features=X.shape[1])\n",
                "        model.reset_count = 0 \n",
                "    \n",
                "    # Train Loop\n",
                "    for epoch in range(EPOCHS_PER_BATCH):\n",
                "        overall_epoch_counter += 1\n",
                "        if overall_epoch_counter % model.decay_steps == 0:\n",
                "            model.learning_rate *= model.decay_rate\n",
                "        model.learning_rates_log.append(model.learning_rate)\n",
                "\n",
                "        for i in range(len(X_train)):\n",
                "            model.update_weights(X_train[i], y_train[i])\n",
                "    \n",
                "    # Validation Loop\n",
                "    val_predictions = model.predict(X_val)\n",
                "    val_acc = accuracy_score(y_val, val_predictions)\n",
                "    global_accuracies.append(val_acc)\n",
                "    print(f\"  Batch {batch_idx+1} Validation Accuracy: {val_acc:.4f}\")\n",
                "    \n",
                "    # Reset Condition\n",
                "    if val_acc < 0.70:\n",
                "        print(f\"  [DRIFT] Accuracy {val_acc:.2f} < 0.70. Drift likely detected.\")\n",
                "        model.reset_model(n_features=X.shape[1])\n",
                "        reset_points.append(batch_idx + 1)\n",
                "        print(\"  [RETRAIN] Retraining on current batch after reset...\")\n",
                "        model.learning_rate = model.initial_learning_rate\n",
                "        for epoch in range(EPOCHS_PER_BATCH):\n",
                "             for i in range(len(X_train)):\n",
                "                model.update_weights(X_train[i], y_train[i])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud83d\udd39 Analysis & Visualization Block\n",
                "#### 3.1 What it does\n",
                "Plots the accuracy over time and marks where Resets happened.\n",
                "#### 3.2 Why it is used\n",
                "Visual proof of the model's performance.\n",
                "#### 3.3 When to use it\n",
                "At the very end.\n",
                "#### 3.4 Where to use it\n",
                "Final cell.\n",
                "#### 3.5 How to use it\n",
                "See code below.\n",
                "#### 3.6 How it works internally\n",
                "Uses `matplotlib.pyplot` to draw lines and markers.\n",
                "#### 3.7 Output impact with examples\n",
                "Displays a graph inline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analysis Output\n",
                "print(\"\\n=== FINAL ANALYSIS ===\")\n",
                "print(f\"Total Resets: {model.reset_count}\")\n",
                "print(f\"Final Batch Accuracy: {global_accuracies[-1]:.4f}\")\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(range(1, len(batches) + 1), global_accuracies, marker='o', linestyle='-', label='Validation Accuracy')\n",
                "plt.axhline(y=0.70, color='r', linestyle='--', label='Reset Threshold (0.70)')\n",
                "plt.axhline(y=0.80, color='g', linestyle='--', label='Success Criteria (0.80)')\n",
                "\n",
                "for rp in reset_points:\n",
                "    plt.axvline(x=rp, color='orange', linestyle=':', label='Weight Reset' if rp == reset_points[0] else \"\")\n",
                "    \n",
                "plt.title('Adaptive Perceptron Accuracy over Drifting Batches')\n",
                "plt.xlabel('Batch Index')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}