# MLP Decision Boundaries: Activation Functions Comparison

## ğŸ¯ Project Overview

This project demonstrates how different activation functions in neural networks create different **decision boundaries** on a non-linearly separable dataset.

### What You'll Learn
- How MLPClassifier works in scikit-learn
- How ReLU, Sigmoid (logistic), and Tanh activations differ in practice
- How to visualize and interpret decision boundaries
- Why activation function choice matters for non-linear data

---

## ğŸ“Š Dataset

**make_moons** from sklearn - a classic non-linearly separable dataset resembling two interleaving half-circles.

```python
from sklearn.datasets import make_moons
X, y = make_moons(n_samples=300, noise=0.2, random_state=42)
```

---

## ğŸ§  Models

Three MLPClassifier models with identical architecture but different activations:

| Model | Activation | Hidden Layer | Neurons |
|-------|------------|--------------|---------|
| Model 1 | ReLU | 1 | 8 |
| Model 2 | Logistic (Sigmoid) | 1 | 8 |
| Model 3 | Tanh | 1 | 8 |

All models use `random_state=42` for fair comparison.

---

## ğŸ“ Project Structure

```
MLP_Decision_Boundaries/
â”œâ”€â”€ README.md
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ mlp_decision_boundaries.ipynb
â”œâ”€â”€ src/
â”‚   â””â”€â”€ mlp_decision_boundaries.py
â”œâ”€â”€ documentation/
â”‚   â”œâ”€â”€ Original_Problem.md
â”‚   â”œâ”€â”€ problem_statement.md
â”‚   â”œâ”€â”€ concepts_explained.md
â”‚   â”œâ”€â”€ observations_and_conclusion.md
â”‚   â”œâ”€â”€ interview_questions.md
â”‚   â”œâ”€â”€ exam_preparation.md
â”‚   â””â”€â”€ interview_preparation.md
â”œâ”€â”€ slides/
â”‚   â”œâ”€â”€ slides.md
â”‚   â””â”€â”€ slides.pdf
â””â”€â”€ outputs/
    â”œâ”€â”€ decision_boundaries.png
    â””â”€â”€ comparison_table.md
```

---

## ğŸš€ How to Run

### Using UV (Recommended)
```powershell
cd c:\masai
uv run python MLP_Decision_Boundaries/src/mlp_decision_boundaries.py
```

### Using Jupyter Notebook
```powershell
cd c:\masai
uv run jupyter lab MLP_Decision_Boundaries/notebook/mlp_decision_boundaries.ipynb
```

---

## ğŸ“ˆ Expected Output

1. **Visualization**: 3-subplot figure showing decision boundaries for each activation
2. **Accuracy Table**: Training accuracy comparison
3. **Written Analysis**: 250-350 word analysis of results
